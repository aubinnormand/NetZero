{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18cd5740-c40d-4e30-b029-4506e57bc221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "import ipynbname \n",
    "import pandas as pd\n",
    "\n",
    "code_path = ipynbname.path().parent.parent\n",
    "# Ajouter le dossier scripts au path\n",
    "scripts_path = code_path  / \"scripts\"\n",
    "sys.path.append(str(scripts_path.resolve()))\n",
    "\n",
    "import data_utils  # importe le module une première fois\n",
    "\n",
    "# Après avoir modifié data_utils.py\n",
    "importlib.reload(data_utils)\n",
    "\n",
    "base_path = code_path.parent\n",
    "# Maintenant tu peux accéder aux fonctions mises à jour\n",
    "from data_utils import import_data_raw, import_data_sig, melt_long_format, clean_year_column, save_long_dataframe, concat_intermediate_files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26406ff-a1f0-4ed3-aeb8-129d900d2ebc",
   "metadata": {},
   "source": [
    "## Importation et formatage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b1f8c37-4003-4114-bb80-72d6f462f0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Afghanistan</th>\n",
       "      <th>Albania</th>\n",
       "      <th>Algeria</th>\n",
       "      <th>Andorra</th>\n",
       "      <th>Angola</th>\n",
       "      <th>Antigua and Barbuda</th>\n",
       "      <th>Argentina</th>\n",
       "      <th>Armenia</th>\n",
       "      <th>Australia</th>\n",
       "      <th>...</th>\n",
       "      <th>United Kingdom</th>\n",
       "      <th>United States of America</th>\n",
       "      <th>Uruguay</th>\n",
       "      <th>Uzbekistan</th>\n",
       "      <th>Vanuatu</th>\n",
       "      <th>Venezuela</th>\n",
       "      <th>Vietnam</th>\n",
       "      <th>Yemen</th>\n",
       "      <th>Zambia</th>\n",
       "      <th>Zimbabwe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1960</td>\n",
       "      <td>4.17891</td>\n",
       "      <td>0.98295</td>\n",
       "      <td>4.38642</td>\n",
       "      <td>0.00563</td>\n",
       "      <td>25.0768</td>\n",
       "      <td>-0.02346</td>\n",
       "      <td>10.17</td>\n",
       "      <td>-0.00933</td>\n",
       "      <td>27.694</td>\n",
       "      <td>...</td>\n",
       "      <td>4.45349</td>\n",
       "      <td>14.81644</td>\n",
       "      <td>3.03836</td>\n",
       "      <td>4.84642</td>\n",
       "      <td>0.16419</td>\n",
       "      <td>32.23863</td>\n",
       "      <td>18.54567</td>\n",
       "      <td>-0.15766</td>\n",
       "      <td>13.8241</td>\n",
       "      <td>4.53668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1961</td>\n",
       "      <td>3.59662</td>\n",
       "      <td>0.7255</td>\n",
       "      <td>1.8356</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>17.26244</td>\n",
       "      <td>-0.02766</td>\n",
       "      <td>14.1064</td>\n",
       "      <td>0.11416</td>\n",
       "      <td>33.07387</td>\n",
       "      <td>...</td>\n",
       "      <td>7.10318</td>\n",
       "      <td>-10.00987</td>\n",
       "      <td>2.21593</td>\n",
       "      <td>4.75608</td>\n",
       "      <td>0.15837</td>\n",
       "      <td>22.70522</td>\n",
       "      <td>16.16189</td>\n",
       "      <td>-0.10315</td>\n",
       "      <td>12.03768</td>\n",
       "      <td>4.20776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1962</td>\n",
       "      <td>3.32416</td>\n",
       "      <td>0.60905</td>\n",
       "      <td>0.8065</td>\n",
       "      <td>0.00565</td>\n",
       "      <td>12.35364</td>\n",
       "      <td>-0.02709</td>\n",
       "      <td>14.34233</td>\n",
       "      <td>0.02598</td>\n",
       "      <td>23.63673</td>\n",
       "      <td>...</td>\n",
       "      <td>7.64517</td>\n",
       "      <td>8.79808</td>\n",
       "      <td>1.46941</td>\n",
       "      <td>4.29027</td>\n",
       "      <td>0.13158</td>\n",
       "      <td>16.16343</td>\n",
       "      <td>14.72754</td>\n",
       "      <td>-0.05754</td>\n",
       "      <td>10.7137</td>\n",
       "      <td>4.01729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1963</td>\n",
       "      <td>3.23023</td>\n",
       "      <td>0.46588</td>\n",
       "      <td>0.2254</td>\n",
       "      <td>0.00443</td>\n",
       "      <td>10.40859</td>\n",
       "      <td>-0.02679</td>\n",
       "      <td>15.20561</td>\n",
       "      <td>0.00352</td>\n",
       "      <td>31.58455</td>\n",
       "      <td>...</td>\n",
       "      <td>5.53469</td>\n",
       "      <td>-7.56161</td>\n",
       "      <td>1.21948</td>\n",
       "      <td>3.8779</td>\n",
       "      <td>0.12169</td>\n",
       "      <td>13.62059</td>\n",
       "      <td>14.42662</td>\n",
       "      <td>-0.02795</td>\n",
       "      <td>9.97474</td>\n",
       "      <td>3.78506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1964</td>\n",
       "      <td>2.79609</td>\n",
       "      <td>0.65877</td>\n",
       "      <td>0.33382</td>\n",
       "      <td>0.00364</td>\n",
       "      <td>8.94263</td>\n",
       "      <td>-0.03112</td>\n",
       "      <td>16.08965</td>\n",
       "      <td>-0.02384</td>\n",
       "      <td>35.6386</td>\n",
       "      <td>...</td>\n",
       "      <td>4.6661</td>\n",
       "      <td>-20.7625</td>\n",
       "      <td>0.71589</td>\n",
       "      <td>3.528</td>\n",
       "      <td>0.47585</td>\n",
       "      <td>11.67585</td>\n",
       "      <td>14.02095</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>9.69592</td>\n",
       "      <td>3.48887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0 Afghanistan  Albania  Algeria  Andorra    Angola  \\\n",
       "0       1960     4.17891  0.98295  4.38642  0.00563   25.0768   \n",
       "1       1961     3.59662   0.7255   1.8356   0.0074  17.26244   \n",
       "2       1962     3.32416  0.60905   0.8065  0.00565  12.35364   \n",
       "3       1963     3.23023  0.46588   0.2254  0.00443  10.40859   \n",
       "4       1964     2.79609  0.65877  0.33382  0.00364   8.94263   \n",
       "\n",
       "  Antigua and Barbuda Argentina   Armenia Australia  ... United Kingdom  \\\n",
       "0            -0.02346     10.17  -0.00933    27.694  ...        4.45349   \n",
       "1            -0.02766   14.1064   0.11416  33.07387  ...        7.10318   \n",
       "2            -0.02709  14.34233   0.02598  23.63673  ...        7.64517   \n",
       "3            -0.02679  15.20561   0.00352  31.58455  ...        5.53469   \n",
       "4            -0.03112  16.08965  -0.02384   35.6386  ...         4.6661   \n",
       "\n",
       "  United States of America  Uruguay Uzbekistan  Vanuatu Venezuela   Vietnam  \\\n",
       "0                 14.81644  3.03836    4.84642  0.16419  32.23863  18.54567   \n",
       "1                -10.00987  2.21593    4.75608  0.15837  22.70522  16.16189   \n",
       "2                  8.79808  1.46941    4.29027  0.13158  16.16343  14.72754   \n",
       "3                 -7.56161  1.21948     3.8779  0.12169  13.62059  14.42662   \n",
       "4                 -20.7625  0.71589      3.528  0.47585  11.67585  14.02095   \n",
       "\n",
       "      Yemen    Zambia Zimbabwe  \n",
       "0  -0.15766   13.8241  4.53668  \n",
       "1  -0.10315  12.03768  4.20776  \n",
       "2  -0.05754   10.7137  4.01729  \n",
       "3  -0.02795   9.97474  3.78506  \n",
       "4   0.00005   9.69592  3.48887  \n",
       "\n",
       "[5 rows x 195 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualisation du fichier\n",
    "filename=\"GCB_NetEmissions_Countries.csv\"\n",
    "filepath= base_path/ \"Data\" / 'data_raw' / filename\n",
    "\n",
    "df = pd.read_csv(filepath, dtype=str,header=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "732e2c27-58f1-43a3-ba4d-f14cb3accbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feuilles dans le fichier : ['Summary', 'Territorial Emissions', 'Consumption Emissions', 'Emissions Transfers', 'Regions']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Afghanistan</th>\n",
       "      <th>Albania</th>\n",
       "      <th>Algeria</th>\n",
       "      <th>Andorra</th>\n",
       "      <th>Angola</th>\n",
       "      <th>Anguilla</th>\n",
       "      <th>Antigua and Barbuda</th>\n",
       "      <th>Argentina</th>\n",
       "      <th>Armenia</th>\n",
       "      <th>...</th>\n",
       "      <th>Asia</th>\n",
       "      <th>Central America</th>\n",
       "      <th>Europe</th>\n",
       "      <th>Middle East</th>\n",
       "      <th>North America</th>\n",
       "      <th>Oceania</th>\n",
       "      <th>South America</th>\n",
       "      <th>Bunkers</th>\n",
       "      <th>Statistical Difference</th>\n",
       "      <th>World</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.8521138750599e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00401202150994847</td>\n",
       "      <td>0</td>\n",
       "      <td>48.2464969314514</td>\n",
       "      <td>0</td>\n",
       "      <td>5.418</td>\n",
       "      <td>0.0305820009434216</td>\n",
       "      <td>0.0256893</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.4210854715202e-14</td>\n",
       "      <td>53.7247802539048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.45060918332</td>\n",
       "      <td>0</td>\n",
       "      <td>6.742</td>\n",
       "      <td>0.0290334908417313</td>\n",
       "      <td>0.0301441</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.105427357601e-15</td>\n",
       "      <td>54.2517867741618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49.24473830895</td>\n",
       "      <td>0</td>\n",
       "      <td>7.335</td>\n",
       "      <td>0.0289450290888339</td>\n",
       "      <td>0.0493654</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.6580487380389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.9561893611538</td>\n",
       "      <td>0</td>\n",
       "      <td>8.26</td>\n",
       "      <td>0.0415723001759676</td>\n",
       "      <td>0.0318038</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.105427357601e-15</td>\n",
       "      <td>59.2895654613298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1854</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60.4710333066774</td>\n",
       "      <td>0</td>\n",
       "      <td>9.084</td>\n",
       "      <td>0.0500891057352644</td>\n",
       "      <td>0.0014707</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4210854715202e-14</td>\n",
       "      <td>69.6065931124127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000207773775566332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121654845785534</td>\n",
       "      <td>0</td>\n",
       "      <td>60.4634048089304</td>\n",
       "      <td>0</td>\n",
       "      <td>10.456</td>\n",
       "      <td>0.0588639963115096</td>\n",
       "      <td>0.0411845</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.4210854715202e-14</td>\n",
       "      <td>71.0316187898205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1856</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0045444</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1049454</td>\n",
       "      <td>64.6237705939835</td>\n",
       "      <td>0</td>\n",
       "      <td>10.9781749</td>\n",
       "      <td>0.0815737600990279</td>\n",
       "      <td>0.1519357</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75.9404003540825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0111237</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0984529</td>\n",
       "      <td>65.0462936367495</td>\n",
       "      <td>0</td>\n",
       "      <td>11.2659992</td>\n",
       "      <td>0.0903658277146707</td>\n",
       "      <td>0.2404409</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.4210854715202e-14</td>\n",
       "      <td>76.7415524644642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1858</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0144018</td>\n",
       "      <td>0.000291767429518679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124749367485013</td>\n",
       "      <td>0.0923615</td>\n",
       "      <td>65.9174383789256</td>\n",
       "      <td>0</td>\n",
       "      <td>11.4432252</td>\n",
       "      <td>0.0929264948628625</td>\n",
       "      <td>0.2628115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77.9335124412735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1859</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0092316</td>\n",
       "      <td>0.000309450304034963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191831889530606</td>\n",
       "      <td>0.0866474</td>\n",
       "      <td>69.5046705677605</td>\n",
       "      <td>0</td>\n",
       "      <td>12.4571777</td>\n",
       "      <td>0.132354671096029</td>\n",
       "      <td>0.20706</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82.5797422283872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 231 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0 Afghanistan Albania Algeria Andorra Angola Anguilla  \\\n",
       "0       1850         NaN     NaN     NaN     NaN    NaN      NaN   \n",
       "1       1851         NaN     NaN     NaN     NaN    NaN      NaN   \n",
       "2       1852         NaN     NaN     NaN     NaN    NaN      NaN   \n",
       "3       1853         NaN     NaN     NaN     NaN    NaN      NaN   \n",
       "4       1854         NaN     NaN     NaN     NaN    NaN      NaN   \n",
       "5       1855         NaN     NaN     NaN     NaN    NaN      NaN   \n",
       "6       1856         NaN     NaN     NaN     NaN    NaN      NaN   \n",
       "7       1857         NaN     NaN     NaN     NaN    NaN      NaN   \n",
       "8       1858         NaN     NaN     NaN     NaN    NaN      NaN   \n",
       "9       1859         NaN     NaN     NaN     NaN    NaN      NaN   \n",
       "\n",
       "  Antigua and Barbuda  Argentina               Armenia  ...  \\\n",
       "0                   0        NaN   6.8521138750599e-05  ...   \n",
       "1                   0        NaN                     0  ...   \n",
       "2                   0        NaN                     0  ...   \n",
       "3                   0        NaN                     0  ...   \n",
       "4                   0        NaN                     0  ...   \n",
       "5                   0        NaN  0.000207773775566332  ...   \n",
       "6                   0  0.0045444                     0  ...   \n",
       "7                   0  0.0111237                     0  ...   \n",
       "8                   0  0.0144018  0.000291767429518679  ...   \n",
       "9                   0  0.0092316  0.000309450304034963  ...   \n",
       "\n",
       "                  Asia Central America            Europe Middle East  \\\n",
       "0  0.00401202150994847               0  48.2464969314514           0   \n",
       "1                    0               0    47.45060918332           0   \n",
       "2                    0               0    49.24473830895           0   \n",
       "3                    0               0  50.9561893611538           0   \n",
       "4                    0               0  60.4710333066774           0   \n",
       "5   0.0121654845785534               0  60.4634048089304           0   \n",
       "6                    0       0.1049454  64.6237705939835           0   \n",
       "7                    0       0.0984529  65.0462936367495           0   \n",
       "8    0.124749367485013       0.0923615  65.9174383789256           0   \n",
       "9    0.191831889530606       0.0866474  69.5046705677605           0   \n",
       "\n",
       "  North America             Oceania South America Bunkers  \\\n",
       "0         5.418  0.0305820009434216     0.0256893       0   \n",
       "1         6.742  0.0290334908417313     0.0301441       0   \n",
       "2         7.335  0.0289450290888339     0.0493654       0   \n",
       "3          8.26  0.0415723001759676     0.0318038       0   \n",
       "4         9.084  0.0500891057352644     0.0014707       0   \n",
       "5        10.456  0.0588639963115096     0.0411845       0   \n",
       "6    10.9781749  0.0815737600990279     0.1519357       0   \n",
       "7    11.2659992  0.0903658277146707     0.2404409       0   \n",
       "8    11.4432252  0.0929264948628625     0.2628115       0   \n",
       "9    12.4571777   0.132354671096029       0.20706       0   \n",
       "\n",
       "  Statistical Difference             World  \n",
       "0   -1.4210854715202e-14  53.7247802539048  \n",
       "1    -7.105427357601e-15  54.2517867741618  \n",
       "2                      0  56.6580487380389  \n",
       "3    -7.105427357601e-15  59.2895654613298  \n",
       "4    1.4210854715202e-14  69.6065931124127  \n",
       "5   -1.4210854715202e-14  71.0316187898205  \n",
       "6                      0  75.9404003540825  \n",
       "7   -1.4210854715202e-14  76.7415524644642  \n",
       "8                      0  77.9335124412735  \n",
       "9                      0  82.5797422283872  \n",
       "\n",
       "[10 rows x 231 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Définir le chemin\n",
    "filename = \"National_Fossil_Carbon_Emissions_2024v1.0-1.xlsx\"\n",
    "filepath = base_path / \"Data\" / 'GHG Datasets' / 'Global Carbon Budget' / filename\n",
    "\n",
    "# Charger le fichier Excel\n",
    "xls = pd.ExcelFile(filepath)\n",
    "\n",
    "# Afficher les noms des feuilles\n",
    "print(\"Feuilles dans le fichier :\", xls.sheet_names)\n",
    "\n",
    "# Lire la première feuille (ou choisir celle que tu veux)\n",
    "df = pd.read_excel(filepath, sheet_name=xls.sheet_names[1], dtype=str, header=11)\n",
    "\n",
    "# Afficher les 20 premières lignes\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5993637-a1c2-4f0c-b99c-135d3ec13556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Afghanistan</th>\n",
       "      <th>Albania</th>\n",
       "      <th>Algeria</th>\n",
       "      <th>Andorra</th>\n",
       "      <th>Angola</th>\n",
       "      <th>Anguilla</th>\n",
       "      <th>Antigua and Barbuda</th>\n",
       "      <th>Argentina</th>\n",
       "      <th>Armenia</th>\n",
       "      <th>...</th>\n",
       "      <th>Asia</th>\n",
       "      <th>Central America</th>\n",
       "      <th>Europe</th>\n",
       "      <th>Middle East</th>\n",
       "      <th>North America</th>\n",
       "      <th>Oceania</th>\n",
       "      <th>South America</th>\n",
       "      <th>Bunkers</th>\n",
       "      <th>Statistical Difference</th>\n",
       "      <th>World</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.246497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.418</td>\n",
       "      <td>0.030582</td>\n",
       "      <td>0.025689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.421085e-14</td>\n",
       "      <td>53.724780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.450609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.742</td>\n",
       "      <td>0.029033</td>\n",
       "      <td>0.030144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.105427e-15</td>\n",
       "      <td>54.251787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.244738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.335</td>\n",
       "      <td>0.028945</td>\n",
       "      <td>0.049365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>56.658049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.956189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.260</td>\n",
       "      <td>0.041572</td>\n",
       "      <td>0.031804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.105427e-15</td>\n",
       "      <td>59.289565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1854</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.471033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.084</td>\n",
       "      <td>0.050089</td>\n",
       "      <td>0.001471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.421085e-14</td>\n",
       "      <td>69.606593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 231 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Afghanistan  Albania  Algeria  Andorra  Angola  Anguilla  \\\n",
       "0  1850          NaN      NaN      NaN      NaN     NaN       NaN   \n",
       "1  1851          NaN      NaN      NaN      NaN     NaN       NaN   \n",
       "2  1852          NaN      NaN      NaN      NaN     NaN       NaN   \n",
       "3  1853          NaN      NaN      NaN      NaN     NaN       NaN   \n",
       "4  1854          NaN      NaN      NaN      NaN     NaN       NaN   \n",
       "\n",
       "   Antigua and Barbuda  Argentina   Armenia  ...      Asia  Central America  \\\n",
       "0                  0.0        NaN  0.000069  ...  0.004012              0.0   \n",
       "1                  0.0        NaN  0.000000  ...  0.000000              0.0   \n",
       "2                  0.0        NaN  0.000000  ...  0.000000              0.0   \n",
       "3                  0.0        NaN  0.000000  ...  0.000000              0.0   \n",
       "4                  0.0        NaN  0.000000  ...  0.000000              0.0   \n",
       "\n",
       "      Europe  Middle East  North America   Oceania  South America  Bunkers  \\\n",
       "0  48.246497          0.0          5.418  0.030582       0.025689      0.0   \n",
       "1  47.450609          0.0          6.742  0.029033       0.030144      0.0   \n",
       "2  49.244738          0.0          7.335  0.028945       0.049365      0.0   \n",
       "3  50.956189          0.0          8.260  0.041572       0.031804      0.0   \n",
       "4  60.471033          0.0          9.084  0.050089       0.001471      0.0   \n",
       "\n",
       "   Statistical Difference      World  \n",
       "0           -1.421085e-14  53.724780  \n",
       "1           -7.105427e-15  54.251787  \n",
       "2            0.000000e+00  56.658049  \n",
       "3           -7.105427e-15  59.289565  \n",
       "4            1.421085e-14  69.606593  \n",
       "\n",
       "[5 rows x 231 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importation\n",
    "df = import_data_raw(filepath, n_header=11, sheet_name=xls.sheet_names[1])\n",
    "df = clean_year_column(df)  # nettoie la colonne Year\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45c5367f-e7e6-4dc4-8656-eaaccb43434a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Country</th>\n",
       "      <th>Value</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Indicator</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1850</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MtC/year</td>\n",
       "      <td>Fossil CO2 emissions</td>\n",
       "      <td>GCB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1851</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MtC/year</td>\n",
       "      <td>Fossil CO2 emissions</td>\n",
       "      <td>GCB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1852</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MtC/year</td>\n",
       "      <td>Fossil CO2 emissions</td>\n",
       "      <td>GCB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1853</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MtC/year</td>\n",
       "      <td>Fossil CO2 emissions</td>\n",
       "      <td>GCB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1854</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MtC/year</td>\n",
       "      <td>Fossil CO2 emissions</td>\n",
       "      <td>GCB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year      Country  Value      Unit             Indicator Source\n",
       "0  1850  Afghanistan    NaN  MtC/year  Fossil CO2 emissions    GCB\n",
       "1  1851  Afghanistan    NaN  MtC/year  Fossil CO2 emissions    GCB\n",
       "2  1852  Afghanistan    NaN  MtC/year  Fossil CO2 emissions    GCB\n",
       "3  1853  Afghanistan    NaN  MtC/year  Fossil CO2 emissions    GCB\n",
       "4  1854  Afghanistan    NaN  MtC/year  Fossil CO2 emissions    GCB"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Passage en format long\n",
    "source=\"GCB\"\n",
    "unit=\"MtC/year\"\n",
    "indicator=\"Fossil CO2 emissions\"\n",
    "df_long = melt_long_format(df, id_vars=['Year'], var_name='Country', value_name='Value', source=source,unit=unit, indicator=indicator)\n",
    "df_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a15e3ddd-58e7-46f5-b84a-caccdaf1adcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_path = ipynbname.path().parent.parent\n",
    "# Ajouter le dossier scripts au path\n",
    "scripts_path = code_path / \"scripts\"\n",
    "base_path = code_path.parent\n",
    "sys.path.append(str(scripts_path.resolve()))\n",
    "\n",
    "import data_utils\n",
    "importlib.reload(data_utils)\n",
    "from data_utils import import_data_raw, import_data_sig\n",
    "\n",
    "\n",
    "# --- Fonctions utilitaires ---\n",
    "def symlog(x):\n",
    "    \"\"\"Logarithme symétrique : log10(|x|+1) * signe(x)\"\"\"\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    return np.sign(x) * np.log10(abs(x) + 1)\n",
    "\n",
    "\n",
    "# --- Charger données ---\n",
    "filename = \"data_final_all_norm.csv\"\n",
    "filepath = base_path / \"Data\" / 'data_final' / filename\n",
    "df_data = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81ffc139-af08-4611-8b5a-838b6e308b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_point_2d</th>\n",
       "      <th>iso3</th>\n",
       "      <th>status</th>\n",
       "      <th>color_code</th>\n",
       "      <th>name</th>\n",
       "      <th>continent</th>\n",
       "      <th>region</th>\n",
       "      <th>iso_3166_1_alpha_2_codes</th>\n",
       "      <th>french_short</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>{ \"lon\": 17.218277596923286, \"lat\": -22.133246...</td>\n",
       "      <td>NAM</td>\n",
       "      <td>Member State</td>\n",
       "      <td>NAM</td>\n",
       "      <td>Namibia</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Southern Africa</td>\n",
       "      <td>NA</td>\n",
       "      <td>Namibie</td>\n",
       "      <td>POLYGON ((23.47611 -17.62584, 23.82083 -17.560...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          geo_point_2d iso3        status  \\\n",
       "182  { \"lon\": 17.218277596923286, \"lat\": -22.133246...  NAM  Member State   \n",
       "\n",
       "    color_code     name continent           region iso_3166_1_alpha_2_codes  \\\n",
       "182        NAM  Namibia    Africa  Southern Africa                       NA   \n",
       "\n",
       "    french_short                                           geometry  \n",
       "182      Namibie  POLYGON ((23.47611 -17.62584, 23.82083 -17.560...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_world[gdf_world['name']=='Namibia']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd2e71f-8cc5-4b81-bc20-115c160941ff",
   "metadata": {},
   "source": [
    "## SIG ET NOM DE PAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd0f0a95-4c40-4d75-bb8f-90d1d9b45a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_point_2d</th>\n",
       "      <th>iso3</th>\n",
       "      <th>status</th>\n",
       "      <th>color_code</th>\n",
       "      <th>name</th>\n",
       "      <th>continent</th>\n",
       "      <th>region</th>\n",
       "      <th>iso_3166_1_alpha_2_codes</th>\n",
       "      <th>french_short</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{ \"lon\": -16.984917430414384, \"lat\": 32.747916...</td>\n",
       "      <td>None</td>\n",
       "      <td>PT Territory</td>\n",
       "      <td>PRT</td>\n",
       "      <td>Madeira Islands</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Southern Europe</td>\n",
       "      <td>None</td>\n",
       "      <td>Madeira Islands</td>\n",
       "      <td>POLYGON ((-17.1025 32.82333, -17.05306 32.8094...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{ \"lon\": 33.743791080217562, \"lat\": 21.8927401...</td>\n",
       "      <td>None</td>\n",
       "      <td>Adm. by EGY</td>\n",
       "      <td>EGY</td>\n",
       "      <td>Ma'tan al-Sarra</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Northern Africa</td>\n",
       "      <td>None</td>\n",
       "      <td>Ma'tan al-Sarra</td>\n",
       "      <td>POLYGON ((33.25104 21.99977, 34.15064 21.99603...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{ \"lon\": 9.5613358449883421, \"lat\": 34.1108585...</td>\n",
       "      <td>TUN</td>\n",
       "      <td>Member State</td>\n",
       "      <td>TUN</td>\n",
       "      <td>Tunisia</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Northern Africa</td>\n",
       "      <td>TN</td>\n",
       "      <td>Tunisie</td>\n",
       "      <td>MULTIPOLYGON (((10.99361 33.75, 10.93778 33.72...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{ \"lon\": 43.77213543247138, \"lat\": 33.04802449...</td>\n",
       "      <td>IRQ</td>\n",
       "      <td>Member State</td>\n",
       "      <td>IRQ</td>\n",
       "      <td>Iraq</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Western Asia</td>\n",
       "      <td>IQ</td>\n",
       "      <td>Iraq</td>\n",
       "      <td>POLYGON ((44.78734 37.14971, 44.76617 37.11228...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{ \"lon\": -6.3178452255610269, \"lat\": 31.883624...</td>\n",
       "      <td>MAR</td>\n",
       "      <td>Member State</td>\n",
       "      <td>MAR</td>\n",
       "      <td>Morocco</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Northern Africa</td>\n",
       "      <td>MA</td>\n",
       "      <td>Maroc</td>\n",
       "      <td>POLYGON ((-2.94694 35.32916, -2.96618 35.31663...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        geo_point_2d  iso3        status  \\\n",
       "0  { \"lon\": -16.984917430414384, \"lat\": 32.747916...  None  PT Territory   \n",
       "1  { \"lon\": 33.743791080217562, \"lat\": 21.8927401...  None   Adm. by EGY   \n",
       "2  { \"lon\": 9.5613358449883421, \"lat\": 34.1108585...   TUN  Member State   \n",
       "3  { \"lon\": 43.77213543247138, \"lat\": 33.04802449...   IRQ  Member State   \n",
       "4  { \"lon\": -6.3178452255610269, \"lat\": 31.883624...   MAR  Member State   \n",
       "\n",
       "  color_code             name continent           region  \\\n",
       "0        PRT  Madeira Islands    Europe  Southern Europe   \n",
       "1        EGY  Ma'tan al-Sarra    Africa  Northern Africa   \n",
       "2        TUN          Tunisia    Africa  Northern Africa   \n",
       "3        IRQ             Iraq      Asia     Western Asia   \n",
       "4        MAR          Morocco    Africa  Northern Africa   \n",
       "\n",
       "  iso_3166_1_alpha_2_codes     french_short  \\\n",
       "0                     None  Madeira Islands   \n",
       "1                     None  Ma'tan al-Sarra   \n",
       "2                       TN          Tunisie   \n",
       "3                       IQ             Iraq   \n",
       "4                       MA            Maroc   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((-17.1025 32.82333, -17.05306 32.8094...  \n",
       "1  POLYGON ((33.25104 21.99977, 34.15064 21.99603...  \n",
       "2  MULTIPOLYGON (((10.99361 33.75, 10.93778 33.72...  \n",
       "3  POLYGON ((44.78734 37.14971, 44.76617 37.11228...  \n",
       "4  POLYGON ((-2.94694 35.32916, -2.96618 35.31663...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importation de fichier SIG\n",
    "gdf_world=import_data_sig(base_path,'world-administrative-boundaries.geojson')\n",
    "#gdf_world[['iso_3166_1_alpha_2_codes', 'name']]\n",
    "\n",
    "gdf_world.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5133f651-8cf7-4dee-881a-2c034cc8c84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_point_2d</th>\n",
       "      <th>iso3</th>\n",
       "      <th>status</th>\n",
       "      <th>color_code</th>\n",
       "      <th>name</th>\n",
       "      <th>continent</th>\n",
       "      <th>region</th>\n",
       "      <th>Country_code</th>\n",
       "      <th>french_short</th>\n",
       "      <th>Country</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{ \"lon\": -16.984917430414384, \"lat\": 32.747916...</td>\n",
       "      <td>None</td>\n",
       "      <td>PT Territory</td>\n",
       "      <td>PRT</td>\n",
       "      <td>Madeira Islands</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Southern Europe</td>\n",
       "      <td>None</td>\n",
       "      <td>Madeira Islands</td>\n",
       "      <td>None</td>\n",
       "      <td>POLYGON ((-17.1025 32.82333, -17.05306 32.8094...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{ \"lon\": 33.743791080217562, \"lat\": 21.8927401...</td>\n",
       "      <td>None</td>\n",
       "      <td>Adm. by EGY</td>\n",
       "      <td>EGY</td>\n",
       "      <td>Ma'tan al-Sarra</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Northern Africa</td>\n",
       "      <td>None</td>\n",
       "      <td>Ma'tan al-Sarra</td>\n",
       "      <td>None</td>\n",
       "      <td>POLYGON ((33.25104 21.99977, 34.15064 21.99603...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{ \"lon\": 9.5613358449883421, \"lat\": 34.1108585...</td>\n",
       "      <td>TUN</td>\n",
       "      <td>Member State</td>\n",
       "      <td>TUN</td>\n",
       "      <td>Tunisia</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Northern Africa</td>\n",
       "      <td>TN</td>\n",
       "      <td>Tunisie</td>\n",
       "      <td>Tunisia</td>\n",
       "      <td>MULTIPOLYGON (((10.99361 33.75, 10.93778 33.72...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{ \"lon\": 43.77213543247138, \"lat\": 33.04802449...</td>\n",
       "      <td>IRQ</td>\n",
       "      <td>Member State</td>\n",
       "      <td>IRQ</td>\n",
       "      <td>Iraq</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Western Asia</td>\n",
       "      <td>IQ</td>\n",
       "      <td>Iraq</td>\n",
       "      <td>Iraq</td>\n",
       "      <td>POLYGON ((44.78734 37.14971, 44.76617 37.11228...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{ \"lon\": -6.3178452255610269, \"lat\": 31.883624...</td>\n",
       "      <td>MAR</td>\n",
       "      <td>Member State</td>\n",
       "      <td>MAR</td>\n",
       "      <td>Morocco</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Northern Africa</td>\n",
       "      <td>MA</td>\n",
       "      <td>Maroc</td>\n",
       "      <td>Morocco</td>\n",
       "      <td>POLYGON ((-2.94694 35.32916, -2.96618 35.31663...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        geo_point_2d  iso3        status  \\\n",
       "0  { \"lon\": -16.984917430414384, \"lat\": 32.747916...  None  PT Territory   \n",
       "1  { \"lon\": 33.743791080217562, \"lat\": 21.8927401...  None   Adm. by EGY   \n",
       "2  { \"lon\": 9.5613358449883421, \"lat\": 34.1108585...   TUN  Member State   \n",
       "3  { \"lon\": 43.77213543247138, \"lat\": 33.04802449...   IRQ  Member State   \n",
       "4  { \"lon\": -6.3178452255610269, \"lat\": 31.883624...   MAR  Member State   \n",
       "\n",
       "  color_code             name continent           region Country_code  \\\n",
       "0        PRT  Madeira Islands    Europe  Southern Europe         None   \n",
       "1        EGY  Ma'tan al-Sarra    Africa  Northern Africa         None   \n",
       "2        TUN          Tunisia    Africa  Northern Africa           TN   \n",
       "3        IRQ             Iraq      Asia     Western Asia           IQ   \n",
       "4        MAR          Morocco    Africa  Northern Africa           MA   \n",
       "\n",
       "      french_short  Country                                           geometry  \n",
       "0  Madeira Islands     None  POLYGON ((-17.1025 32.82333, -17.05306 32.8094...  \n",
       "1  Ma'tan al-Sarra     None  POLYGON ((33.25104 21.99977, 34.15064 21.99603...  \n",
       "2          Tunisie  Tunisia  MULTIPOLYGON (((10.99361 33.75, 10.93778 33.72...  \n",
       "3             Iraq     Iraq  POLYGON ((44.78734 37.14971, 44.76617 37.11228...  \n",
       "4            Maroc  Morocco  POLYGON ((-2.94694 35.32916, -2.96618 35.31663...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importation de fichier SIG\n",
    "gdf_world=import_data_sig(base_path,'world.geojson')\n",
    "#gdf_world[['iso_3166_1_alpha_2_codes', 'name']]\n",
    "\n",
    "gdf_world.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcba416f-aa57-4be4-bb6e-5316562e46bd",
   "metadata": {},
   "source": [
    "### OPTIONAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acfdae6-fdca-47b2-ad69-7a428d7ebbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Fusion des deux tables\n",
    "df_merged = df_long.merge(\n",
    "    gdf_world[['iso_3166_1_alpha_2_codes', 'name']],\n",
    "    left_on='Country',\n",
    "    right_on='name',\n",
    "    how='outer',  # on garde tout pour pouvoir identifier les non-correspondances\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# --- Identifier les correspondances et les non-correspondances ---\n",
    "# Country sans équivalent dans gdf_world['name']\n",
    "country_sans_name = df_merged[df_merged['_merge'] == 'left_only'][['Country']].drop_duplicates()\n",
    "\n",
    "# name sans équivalent dans df_final['Country']\n",
    "name_sans_country = df_merged[df_merged['_merge'] == 'right_only'][['name']].drop_duplicates()\n",
    "\n",
    "# Comptage\n",
    "print(f\"Nombre de 'Country' sans équivalent : {len(country_sans_name)}\")\n",
    "print(f\"Nombre de 'name' sans équivalent : {len(name_sans_country)}\")\n",
    "\n",
    "# Optionnel : garder seulement les ligne\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b386cc7-b6f1-4904-b23c-e1d81a7bb44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_sans_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83827734-b321-4491-bddf-435781667817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🌍 Nom : Netherlands Antilles (FR : Netherlands Antilles)\n",
      "→ Correspondances par inclusion :\n",
      "  [0] Netherlands\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Sélectionner le numéro de la correspondance à valider (Entrée pour ignorer) :  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Aucune correspondance validée pour Netherlands Antilles\n",
      "\n",
      "🌍 Nom : British Indian Ocean Territory (FR : British Indian Ocean Territory)\n",
      "→ Correspondances par inclusion :\n",
      "  [0] India\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Sélectionner le numéro de la correspondance à valider (Entrée pour ignorer) :  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Aucune correspondance validée pour British Indian Ocean Territory\n",
      "\n",
      "🌍 Nom : Antigua & Barbuda (FR : Antigua-et-Barbuda)\n",
      "→ Correspondances floues potentielles dans df_merged['Country'] :\n",
      "  [0] Antigua and Barbuda\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Sélectionner le numéro de la correspondance à valider (Entrée pour ignorer) :  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Correspondance validée (floue) : Antigua & Barbuda → Antigua and Barbuda\n",
      "\n",
      "🌍 Nom : United Republic of Tanzania (FR : République-Unie de Tanzanie)\n",
      "→ Correspondances par inclusion :\n",
      "  [0] Tanzania\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Sélectionner le numéro de la correspondance à valider (Entrée pour ignorer) :  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Correspondance validée (inclusion) : United Republic of Tanzania → Tanzania\n",
      "\n",
      "🌍 Nom : Moldova, Republic of (FR : République de Moldova)\n",
      "→ Correspondances par inclusion :\n",
      "  [0] Moldova\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Sélectionner le numéro de la correspondance à valider (Entrée pour ignorer) :  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Correspondance validée (inclusion) : Moldova, Republic of → Moldova\n",
      "\n",
      "🌍 Nom : Syrian Arab Republic (FR : République arabe syrienne)\n",
      "→ Correspondances par inclusion :\n",
      "  [0] Syria\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Sélectionner le numéro de la correspondance à valider (Entrée pour ignorer) :  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Correspondance validée (inclusion) : Syrian Arab Republic → Syria\n",
      "\n",
      "🌍 Nom : Libyan Arab Jamahiriya (FR : Libye)\n",
      "→ Correspondances par inclusion :\n",
      "  [0] Libya\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Sélectionner le numéro de la correspondance à valider (Entrée pour ignorer) :  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Correspondance validée (inclusion) : Libyan Arab Jamahiriya → Libya\n",
      "\n",
      "🌍 Nom : U.K. of Great Britain and Northern Ireland (FR : Royaume-Uni de Grande-Bretagne et d'Irlande du Nord)\n",
      "→ Correspondances par inclusion :\n",
      "  [0] Ireland\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Sélectionner le numéro de la correspondance à valider (Entrée pour ignorer) :  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Aucune correspondance validée pour U.K. of Great Britain and Northern Ireland\n",
      "\n",
      "🌍 Nom : South Sudan (FR : Soudan du Sud)\n",
      "→ Correspondances par inclusion :\n",
      "  [0] Republic of South Sudan\n",
      "  [1] Sudan\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Sélectionner le numéro de la correspondance à valider (Entrée pour ignorer) :  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Correspondance validée (inclusion) : South Sudan → Republic of South Sudan\n",
      "\n",
      "🌍 Nom : American Samoa (FR : American Samoa)\n",
      "→ Correspondances par inclusion :\n",
      "  [0] Samoa\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Sélectionner le numéro de la correspondance à valider (Entrée pour ignorer) :  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Aucune correspondance validée pour American Samoa\n",
      "\n",
      "🌍 Nom : South Georgia & the South Sandwich Islands (FR : South Georgia & the South Sandwich Islands)\n",
      "→ Correspondances par inclusion :\n",
      "  [0] Georgia\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Sélectionner le numéro de la correspondance à valider (Entrée pour ignorer) :  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Aucune correspondance validée pour South Georgia & the South Sandwich Islands\n",
      "\n",
      "🌍 Nom : Bosnia & Herzegovina (FR : Bosnie-Herzégovine)\n",
      "→ Correspondances floues potentielles dans df_merged['Country'] :\n",
      "  [0] Bosnia and Herzegovina\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Sélectionner le numéro de la correspondance à valider (Entrée pour ignorer) :  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Correspondance validée (floue) : Bosnia & Herzegovina → Bosnia and Herzegovina\n",
      "\n",
      "✅ Mise à jour terminée.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from difflib import get_close_matches\n",
    "\n",
    "# --- Préparation ---\n",
    "countries = df_long['Country'].dropna().unique()\n",
    "gdf_world['Country'] = None  # colonne à créer/remplir\n",
    "\n",
    "from difflib import get_close_matches\n",
    "\n",
    "# --- Fonction utilitaire pour trouver les meilleures correspondances ---\n",
    "def find_best_match(target, candidates, cutoff=0.8):\n",
    "    \"\"\"Retourne les meilleures correspondances au-dessus du seuil de similarité.\"\"\"\n",
    "    return get_close_matches(target, candidates, n=5, cutoff=cutoff)\n",
    "\n",
    "# --- Itération sur les lignes de gdf_world ---\n",
    "for idx, row in gdf_world.iterrows():\n",
    "    name = str(row['name'])\n",
    "    french = str(row.get('french_short', '') or '')\n",
    "    candidates = list(countries)\n",
    "\n",
    "    # --- 1️⃣ Correspondance exacte ---\n",
    "    exact_match = next(\n",
    "        (c for c in candidates if c.lower() == name.lower() or c.lower() == french.lower()), \n",
    "        None\n",
    "    )\n",
    "    if exact_match:\n",
    "        gdf_world.at[idx, 'Country'] = exact_match\n",
    "        continue\n",
    "\n",
    "    # --- 2️⃣ Correspondance par inclusion (dans un sens ou l’autre) ---\n",
    "    inclusions = [\n",
    "        c for c in candidates\n",
    "        if name.lower() in c.lower() or c.lower() in name.lower()\n",
    "        or french.lower() in c.lower() or c.lower() in french.lower()\n",
    "    ]\n",
    "    if inclusions:\n",
    "        print(f\"\\n🌍 Nom : {name} (FR : {french})\")\n",
    "        print(\"→ Correspondances par inclusion :\")\n",
    "        for i, c in enumerate(inclusions):\n",
    "            print(f\"  [{i}] {c}\")\n",
    "        choix = input(\"Sélectionner le numéro de la correspondance à valider (Entrée pour ignorer) : \")\n",
    "\n",
    "        if choix.isdigit() and int(choix) < len(inclusions):\n",
    "            gdf_world.at[idx, 'Country'] = inclusions[int(choix)]\n",
    "            print(f\"✅ Correspondance validée (inclusion) : {name} → {inclusions[int(choix)]}\")\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"❌ Aucune correspondance validée pour {name}\")\n",
    "\n",
    "    # --- 3️⃣ Correspondance floue (difflib) ---\n",
    "    matches_name = find_best_match(name, candidates)\n",
    "    matches_fr = find_best_match(french, candidates) if french else []\n",
    "    all_matches = list(dict.fromkeys(matches_name + matches_fr))  # fusion sans doublons\n",
    "\n",
    "    if all_matches:\n",
    "        print(f\"\\n🌍 Nom : {name} (FR : {french})\")\n",
    "        print(\"→ Correspondances floues potentielles dans df_merged['Country'] :\")\n",
    "        for i, c in enumerate(all_matches):\n",
    "            print(f\"  [{i}] {c}\")\n",
    "        choix = input(\"Sélectionner le numéro de la correspondance à valider (Entrée pour ignorer) : \")\n",
    "\n",
    "        if choix.isdigit() and int(choix) < len(all_matches):\n",
    "            gdf_world.at[idx, 'Country'] = all_matches[int(choix)]\n",
    "            print(f\"✅ Correspondance validée (floue) : {name} → {all_matches[int(choix)]}\")\n",
    "        else:\n",
    "            print(f\"❌ Aucune correspondance validée pour {name}\")\n",
    "\n",
    "print(\"\\n✅ Mise à jour terminée.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfd33b6a-346c-40e8-aa11-512452fa20bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fichier enregistré : C:\\Users\\Aubin\\Documents\\NetZero\\Data\\SIG\\world.geojson\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarde du GeoDataFrame mis à jour en GeoJSON\n",
    "filepath= base_path/ \"Data\" / 'SIG' / \"world.geojson\"\n",
    "gdf_world = gdf_world.rename(columns={'iso_3166_1_alpha_2_codes': 'Country_code'})\n",
    "\n",
    "gdf_world.to_file(filepath, driver=\"GeoJSON\", encoding=\"utf-8\")\n",
    "\n",
    "print(f\"✅ Fichier enregistré : {filepath}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059cd82c-c81f-4da8-87e5-890ec39d6e51",
   "metadata": {},
   "source": [
    "### GO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1fa60f46-41a8-40d0-ad27-bd016fa9e379",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fusion terminée.\n",
      "Lignes fusionnées : 40194\n",
      "Lignes sans correspondance de code pays : 8526\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sélectionner et renommer la colonne color_code\n",
    "\n",
    "# Fusionner avec df_merged\n",
    "df_merged = df_long.merge(\n",
    "    gdf_world[['Country_code', 'Country']],\n",
    "    on='Country',\n",
    "    how='left'  # garde tous les pays de df_merged\n",
    ")\n",
    "\n",
    "# Vérifier que la colonne existe\n",
    "if 'Country_code' not in df_merged.columns:\n",
    "    df_merged['Country_code'] = pd.NA\n",
    "\n",
    "\n",
    "print(\"✅ Fusion terminée.\")\n",
    "print(f\"Lignes fusionnées : {len(df_merged)}\")\n",
    "print(f\"Lignes sans correspondance de code pays : {df_merged['Country_code'].isna().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "05701279-aecc-4816-8b6a-e5ea7e5affc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌍 Nombre de pays sans correspondance : 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anguilla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aruba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bermuda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bonaire, Saint Eustatius and Saba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>British Virgin Islands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bunkers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Central America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Curaçao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Czechia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>EU27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Eswatini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Faeroe Islands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>French Polynesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Greenland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Hong Kong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KP Annex B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Kosovo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Laos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Macao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Middle East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Montserrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>New Caledonia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Non KP Annex B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Non-OECD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>North Korea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>North Macedonia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>OECD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Oceania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Russia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Saint Helena</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Saint Pierre and Miquelon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Sint Maarten (Dutch part)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>South America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>South Korea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>South Sudan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>State of Palestine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Statistical Difference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Taiwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Turks and Caicos Islands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Türkiye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Viet Nam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Wallis and Futuna Islands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Country\n",
       "0                              Africa\n",
       "1                            Anguilla\n",
       "2                               Aruba\n",
       "3                                Asia\n",
       "4                             Bermuda\n",
       "5   Bonaire, Saint Eustatius and Saba\n",
       "6              British Virgin Islands\n",
       "7                             Bunkers\n",
       "8                     Central America\n",
       "9                             Curaçao\n",
       "10                            Czechia\n",
       "11                               EU27\n",
       "12                           Eswatini\n",
       "13                             Europe\n",
       "14                     Faeroe Islands\n",
       "15                   French Polynesia\n",
       "16                          Greenland\n",
       "17                          Hong Kong\n",
       "18                         KP Annex B\n",
       "19                             Kosovo\n",
       "20                               Laos\n",
       "21                              Macao\n",
       "22                        Middle East\n",
       "23                         Montserrat\n",
       "24                      New Caledonia\n",
       "25                     Non KP Annex B\n",
       "26                           Non-OECD\n",
       "27                      North America\n",
       "28                        North Korea\n",
       "29                    North Macedonia\n",
       "30                               OECD\n",
       "31                            Oceania\n",
       "32                             Russia\n",
       "33                       Saint Helena\n",
       "34          Saint Pierre and Miquelon\n",
       "35          Sint Maarten (Dutch part)\n",
       "36                      South America\n",
       "37                        South Korea\n",
       "38                        South Sudan\n",
       "39                 State of Palestine\n",
       "40             Statistical Difference\n",
       "41                             Taiwan\n",
       "42           Turks and Caicos Islands\n",
       "43                            Türkiye\n",
       "44                                USA\n",
       "45                     United Kingdom\n",
       "46                           Viet Nam\n",
       "47          Wallis and Futuna Islands\n",
       "48                              World"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filtrer les pays sans correspondance\n",
    "countries_without_match = df_merged[df_merged['Country_code'].isna()]['Country'].dropna().drop_duplicates().sort_values()\n",
    "\n",
    "# Afficher le résultat\n",
    "print(f\"🌍 Nombre de pays sans correspondance : {len(countries_without_match)}\")\n",
    "display(countries_without_match.to_frame().reset_index(drop=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "58a820ae-e4ab-4f9a-a43d-c245fa4e116e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔎 49 pays sans Country_code.\n",
      "\n",
      "\n",
      "🌍 Pays : Anguilla\n",
      "→ Code trouvé automatiquement depuis CSV : AI\n",
      "✅ Country_code ajouté : Anguilla → AI\n",
      "\n",
      "🌍 Pays : Aruba\n",
      "→ Code trouvé automatiquement depuis CSV : AW\n",
      "✅ Country_code ajouté : Aruba → AW\n",
      "\n",
      "🌍 Pays : Bermuda\n",
      "→ Code trouvé automatiquement depuis CSV : BM\n",
      "✅ Country_code ajouté : Bermuda → BM\n",
      "\n",
      "🌍 Pays : Bonaire, Saint Eustatius and Saba\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrer le Country_code ISO correspondant (ou Entrée pour ignorer) :  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️ Ignoré.\n",
      "\n",
      "🌍 Pays : British Virgin Islands\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrer le Country_code ISO correspondant (ou Entrée pour ignorer) :  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️ Ignoré.\n",
      "\n",
      "🌍 Pays : Curaçao\n",
      "→ Code trouvé automatiquement depuis CSV : CW\n",
      "✅ Country_code ajouté : Curaçao → CW\n",
      "\n",
      "🌍 Pays : Czechia\n",
      "→ Code trouvé automatiquement depuis CSV : CZ\n",
      "✅ Country_code ajouté : Czechia → CZ\n",
      "\n",
      "🌍 Pays : North Korea\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrer le Country_code ISO correspondant (ou Entrée pour ignorer) :  KP\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Country_code ajouté : North Korea → KP\n",
      "\n",
      "🌍 Pays : Faeroe Islands\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrer le Country_code ISO correspondant (ou Entrée pour ignorer) :  FO\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Country_code ajouté : Faeroe Islands → FO\n",
      "\n",
      "🌍 Pays : French Polynesia\n",
      "→ Code trouvé automatiquement depuis CSV : PF\n",
      "✅ Country_code ajouté : French Polynesia → PF\n",
      "\n",
      "🌍 Pays : Greenland\n",
      "→ Code trouvé automatiquement depuis CSV : GL\n",
      "✅ Country_code ajouté : Greenland → GL\n",
      "\n",
      "🌍 Pays : Hong Kong\n",
      "→ Code trouvé automatiquement depuis CSV : HK\n",
      "✅ Country_code ajouté : Hong Kong → HK\n",
      "\n",
      "🌍 Pays : Kosovo\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrer le Country_code ISO correspondant (ou Entrée pour ignorer) :  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️ Ignoré.\n",
      "\n",
      "🌍 Pays : Laos\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrer le Country_code ISO correspondant (ou Entrée pour ignorer) :  LA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Country_code ajouté : Laos → LA\n",
      "\n",
      "🌍 Pays : Macao\n",
      "→ Code trouvé automatiquement depuis CSV : MO\n",
      "✅ Country_code ajouté : Macao → MO\n",
      "\n",
      "🌍 Pays : North Macedonia\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrer le Country_code ISO correspondant (ou Entrée pour ignorer) :  MK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Country_code ajouté : North Macedonia → MK\n",
      "\n",
      "🌍 Pays : Montserrat\n",
      "→ Code trouvé automatiquement depuis CSV : MS\n",
      "✅ Country_code ajouté : Montserrat → MS\n",
      "\n",
      "🌍 Pays : New Caledonia\n",
      "→ Code trouvé automatiquement depuis CSV : NC\n",
      "✅ Country_code ajouté : New Caledonia → NC\n",
      "\n",
      "🌍 Pays : State of Palestine\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrer le Country_code ISO correspondant (ou Entrée pour ignorer) :  PS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Country_code ajouté : State of Palestine → PS\n",
      "\n",
      "🌍 Pays : South Korea\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrer le Country_code ISO correspondant (ou Entrée pour ignorer) :  KR\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Country_code ajouté : South Korea → KR\n",
      "\n",
      "🌍 Pays : South Sudan\n",
      "→ Code trouvé automatiquement depuis CSV : SS\n",
      "✅ Country_code ajouté : South Sudan → SS\n",
      "\n",
      "🌍 Pays : Russia\n",
      "→ Suggestions depuis gdf_world :\n",
      "  [108] Russian Federation → RU\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrer le Country_code ISO correspondant (ou Entrée pour ignorer) :  RU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Country_code ajouté : Russia → RU\n",
      "\n",
      "🌍 Pays : Saint Helena\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrer le Country_code ISO correspondant (ou Entrée pour ignorer) :  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️ Ignoré.\n",
      "\n",
      "🌍 Pays : Sint Maarten (Dutch part)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aubin\\AppData\\Local\\Temp\\ipykernel_18264\\2853083755.py:39: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  suggestions = gdf_world[gdf_world['Country'].str.contains(c, case=False, na=False)]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrer le Country_code ISO correspondant (ou Entrée pour ignorer) :  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️ Ignoré.\n",
      "\n",
      "🌍 Pays : Saint Pierre and Miquelon\n",
      "→ Code trouvé automatiquement depuis CSV : PM\n",
      "✅ Country_code ajouté : Saint Pierre and Miquelon → PM\n",
      "\n",
      "🌍 Pays : Eswatini\n",
      "→ Code trouvé automatiquement depuis CSV : SZ\n",
      "✅ Country_code ajouté : Eswatini → SZ\n",
      "\n",
      "🌍 Pays : Taiwan\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrer le Country_code ISO correspondant (ou Entrée pour ignorer) :  TW\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Country_code ajouté : Taiwan → TW\n",
      "\n",
      "🌍 Pays : Türkiye\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrer le Country_code ISO correspondant (ou Entrée pour ignorer) :  TR\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Country_code ajouté : Türkiye → TR\n",
      "\n",
      "🌍 Pays : Turks and Caicos Islands\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrer le Country_code ISO correspondant (ou Entrée pour ignorer) :  TC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Country_code ajouté : Turks and Caicos Islands → TC\n",
      "\n",
      "🌍 Pays : United Kingdom\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrer le Country_code ISO correspondant (ou Entrée pour ignorer) :  GB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Country_code ajouté : United Kingdom → GB\n",
      "\n",
      "🌍 Pays : USA\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrer le Country_code ISO correspondant (ou Entrée pour ignorer) :  US\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Country_code ajouté : USA → US\n",
      "\n",
      "🌍 Pays : Viet Nam\n",
      "→ Code trouvé automatiquement depuis CSV : VN\n",
      "✅ Country_code ajouté : Viet Nam → VN\n",
      "\n",
      "🌍 Pays : Wallis and Futuna Islands\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrer le Country_code ISO correspondant (ou Entrée pour ignorer) :  WF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Country_code ajouté : Wallis and Futuna Islands → WF\n",
      "\n",
      "🌍 Pays : KP Annex B\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrer le Country_code ISO correspondant (ou Entrée pour ignorer) :  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️ Ignoré.\n",
      "\n",
      "🌍 Pays : Non KP Annex B\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrer le Country_code ISO correspondant (ou Entrée pour ignorer) :  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️ Ignoré.\n",
      "\n",
      "🌍 Pays : OECD\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrer le Country_code ISO correspondant (ou Entrée pour ignorer) :  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️ Ignoré.\n",
      "\n",
      "🌍 Pays : Non-OECD\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrer le Country_code ISO correspondant (ou Entrée pour ignorer) :  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️ Ignoré.\n",
      "\n",
      "🌍 Pays : EU27\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrer le Country_code ISO correspondant (ou Entrée pour ignorer) :  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️ Ignoré.\n",
      "\n",
      "🌍 Pays : Africa\n",
      "→ Suggestions depuis gdf_world :\n",
      "  [5] South Africa → ZA\n",
      "  [147] Central African Republic → CF\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrer le Country_code ISO correspondant (ou Entrée pour ignorer) :  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️ Ignoré.\n",
      "\n",
      "🌍 Pays : Asia\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrer le Country_code ISO correspondant (ou Entrée pour ignorer) :  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️ Ignoré.\n",
      "\n",
      "🌍 Pays : Central America\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrer le Country_code ISO correspondant (ou Entrée pour ignorer) :  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️ Ignoré.\n",
      "\n",
      "🌍 Pays : Europe\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrer le Country_code ISO correspondant (ou Entrée pour ignorer) :  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️ Ignoré.\n",
      "\n",
      "🌍 Pays : Middle East\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrer le Country_code ISO correspondant (ou Entrée pour ignorer) :  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️ Ignoré.\n",
      "\n",
      "🌍 Pays : North America\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrer le Country_code ISO correspondant (ou Entrée pour ignorer) :  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️ Ignoré.\n",
      "\n",
      "🌍 Pays : Oceania\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrer le Country_code ISO correspondant (ou Entrée pour ignorer) :  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️ Ignoré.\n",
      "\n",
      "🌍 Pays : South America\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrer le Country_code ISO correspondant (ou Entrée pour ignorer) :  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️ Ignoré.\n",
      "\n",
      "🌍 Pays : Bunkers\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrer le Country_code ISO correspondant (ou Entrée pour ignorer) :  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️ Ignoré.\n",
      "\n",
      "🌍 Pays : Statistical Difference\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrer le Country_code ISO correspondant (ou Entrée pour ignorer) :  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️ Ignoré.\n",
      "\n",
      "🌍 Pays : World\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrer le Country_code ISO correspondant (ou Entrée pour ignorer) :  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️ Ignoré.\n",
      "\n",
      "✅ Saisie automatique et manuelle des codes terminée.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def manual_country_code_match(df_merged, gdf_world, country_codes_path):\n",
    "    \"\"\"\n",
    "    Complète manuellement ou automatiquement les codes ISO (Country_code) pour les pays\n",
    "    de df_merged qui n'ont pas de correspondance dans gdf_world['Country_code'].\n",
    "    \n",
    "    Args:\n",
    "        df_merged: DataFrame avec une colonne 'Country' et éventuellement 'Country_code'.\n",
    "        gdf_world: GeoDataFrame avec colonnes 'Country' et 'Country_code'.\n",
    "        country_codes_path: chemin vers le fichier CSV contenant les codes ISO (Country, Alpha-2, Alpha-3, Numeric).\n",
    "        \n",
    "    Returns:\n",
    "        df_merged avec la colonne 'Country_code' complétée.\n",
    "    \"\"\"\n",
    "    # Charger le fichier CSV des codes ISO\n",
    "    country_codes_df = pd.read_csv(country_codes_path)\n",
    "    \n",
    "    # Créer un mapping existant depuis gdf_world\n",
    "    existing_mapping = gdf_world.set_index('Country')['Country_code'].to_dict()\n",
    "\n",
    "    # Créer un mapping depuis le CSV\n",
    "    csv_mapping = country_codes_df.set_index('Country')['Alpha-2 code'].to_dict()\n",
    "\n",
    "    # Identifier les pays sans code\n",
    "    unmatched_countries = df_merged.loc[~df_merged['Country'].isin(existing_mapping.keys()), 'Country'].dropna().unique()\n",
    "    \n",
    "    print(f\"\\n🔎 {len(unmatched_countries)} pays sans Country_code.\\n\")\n",
    "\n",
    "    for c in unmatched_countries:\n",
    "        print(f\"\\n🌍 Pays : {c}\")\n",
    "\n",
    "        # Vérifier si le CSV contient le pays\n",
    "        if c in csv_mapping:\n",
    "            saisie = csv_mapping[c]\n",
    "            print(f\"→ Code trouvé automatiquement depuis CSV : {saisie}\")\n",
    "        else:\n",
    "            # Sinon, proposer des suggestions depuis gdf_world\n",
    "            suggestions = gdf_world[gdf_world['Country'].str.contains(c, case=False, na=False)]\n",
    "            if not suggestions.empty:\n",
    "                print(\"→ Suggestions depuis gdf_world :\")\n",
    "                for i, row in suggestions.iterrows():\n",
    "                    print(f\"  [{i}] {row['Country']} → {row['Country_code']}\")\n",
    "            # Demander la saisie manuelle\n",
    "            saisie = input(\"Entrer le Country_code ISO correspondant (ou Entrée pour ignorer) : \").strip().upper()\n",
    "            if saisie == \"\":\n",
    "                print(\"⏭️ Ignoré.\")\n",
    "                continue\n",
    "        \n",
    "        # Remplir df_merged avec le code trouvé ou saisi\n",
    "        df_merged.loc[df_merged['Country'] == c, 'Country_code'] = saisie\n",
    "        print(f\"✅ Country_code ajouté : {c} → {saisie}\")\n",
    "\n",
    "    print(\"\\n✅ Saisie automatique et manuelle des codes terminée.\")\n",
    "    return df_merged\n",
    "\n",
    "# Exemple d'appel\n",
    "df_merged = manual_country_code_match(df_merged, gdf_world, r\"C:\\Users\\Aubin\\Documents\\NetZero\\Data\\SIG\\country_codes.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c2a037-466c-44e5-aebe-a04be44f28d1",
   "metadata": {},
   "source": [
    "## DF FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e6e752f2-32a6-4bc9-8467-08769b515df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame sauvegardé dans C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\Fossil_CO2_emissions_GCB.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/Aubin/Documents/NetZero/Data/data_intermediate/Fossil_CO2_emissions_GCB.csv')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#enregistrer dans data_intermediate\n",
    "save_long_dataframe(\n",
    "    df_merged,\n",
    "    base_path,\n",
    "    folder='data_intermediate',\n",
    "    indicator=indicator,\n",
    "    source=source\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "192fd9f7-eab8-41dd-9215-81d4be2f0186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Country</th>\n",
       "      <th>Value</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Indicator</th>\n",
       "      <th>Source</th>\n",
       "      <th>Country_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1850</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MtC/year</td>\n",
       "      <td>Fossil CO2 emissions</td>\n",
       "      <td>GCB</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1851</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MtC/year</td>\n",
       "      <td>Fossil CO2 emissions</td>\n",
       "      <td>GCB</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1852</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MtC/year</td>\n",
       "      <td>Fossil CO2 emissions</td>\n",
       "      <td>GCB</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1853</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MtC/year</td>\n",
       "      <td>Fossil CO2 emissions</td>\n",
       "      <td>GCB</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1854</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MtC/year</td>\n",
       "      <td>Fossil CO2 emissions</td>\n",
       "      <td>GCB</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40189</th>\n",
       "      <td>2019</td>\n",
       "      <td>World</td>\n",
       "      <td>10126.713389</td>\n",
       "      <td>MtC/year</td>\n",
       "      <td>Fossil CO2 emissions</td>\n",
       "      <td>GCB</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40190</th>\n",
       "      <td>2020</td>\n",
       "      <td>World</td>\n",
       "      <td>9586.933986</td>\n",
       "      <td>MtC/year</td>\n",
       "      <td>Fossil CO2 emissions</td>\n",
       "      <td>GCB</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40191</th>\n",
       "      <td>2021</td>\n",
       "      <td>World</td>\n",
       "      <td>10095.997892</td>\n",
       "      <td>MtC/year</td>\n",
       "      <td>Fossil CO2 emissions</td>\n",
       "      <td>GCB</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40192</th>\n",
       "      <td>2022</td>\n",
       "      <td>World</td>\n",
       "      <td>10178.448797</td>\n",
       "      <td>MtC/year</td>\n",
       "      <td>Fossil CO2 emissions</td>\n",
       "      <td>GCB</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40193</th>\n",
       "      <td>2023</td>\n",
       "      <td>World</td>\n",
       "      <td>10314.292770</td>\n",
       "      <td>MtC/year</td>\n",
       "      <td>Fossil CO2 emissions</td>\n",
       "      <td>GCB</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40194 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year      Country         Value      Unit             Indicator Source  \\\n",
       "0      1850  Afghanistan           NaN  MtC/year  Fossil CO2 emissions    GCB   \n",
       "1      1851  Afghanistan           NaN  MtC/year  Fossil CO2 emissions    GCB   \n",
       "2      1852  Afghanistan           NaN  MtC/year  Fossil CO2 emissions    GCB   \n",
       "3      1853  Afghanistan           NaN  MtC/year  Fossil CO2 emissions    GCB   \n",
       "4      1854  Afghanistan           NaN  MtC/year  Fossil CO2 emissions    GCB   \n",
       "...     ...          ...           ...       ...                   ...    ...   \n",
       "40189  2019        World  10126.713389  MtC/year  Fossil CO2 emissions    GCB   \n",
       "40190  2020        World   9586.933986  MtC/year  Fossil CO2 emissions    GCB   \n",
       "40191  2021        World  10095.997892  MtC/year  Fossil CO2 emissions    GCB   \n",
       "40192  2022        World  10178.448797  MtC/year  Fossil CO2 emissions    GCB   \n",
       "40193  2023        World  10314.292770  MtC/year  Fossil CO2 emissions    GCB   \n",
       "\n",
       "      Country_code  \n",
       "0               AF  \n",
       "1               AF  \n",
       "2               AF  \n",
       "3               AF  \n",
       "4               AF  \n",
       "...            ...  \n",
       "40189          NaN  \n",
       "40190          NaN  \n",
       "40191          NaN  \n",
       "40192          NaN  \n",
       "40193          NaN  \n",
       "\n",
       "[40194 rows x 7 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76da72ef-a7d2-472d-9207-6065cd8c1223",
   "metadata": {},
   "source": [
    "###  CHANGE UNIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c21425b-ea49-430b-a79c-42f6b9413628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def browse_and_convert_units(\n",
    "        base_path,\n",
    "        folder_in=\"data_intermediate\",\n",
    "        value_col=\"Value\",\n",
    "        unit_col=\"Unit\",\n",
    "        sep=\",\",\n",
    "        encoding=\"utf-8\"\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Parcourt tous les fichiers CSV du dossier, demande si on veut changer l'unité\n",
    "    et applique la conversion directement dans chaque fichier.\n",
    "\n",
    "    Paramètres :\n",
    "    - base_path : Path de base\n",
    "    - folder_in : dossier contenant les CSV\n",
    "    - value_col : colonne des valeurs\n",
    "    - unit_col : colonne de l'unité\n",
    "    \"\"\"\n",
    "\n",
    "    import pandas as pd\n",
    "    from pathlib import Path\n",
    "    import glob\n",
    "\n",
    "    # Construire le chemin des fichiers\n",
    "    folder_path = base_path / \"Data\" / folder_in\n",
    "    files = glob.glob(str(folder_path / \"*.csv\"))\n",
    "\n",
    "    if not files:\n",
    "        print(f\"Aucun fichier CSV trouvé dans {folder_path}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"🔍 {len(files)} fichiers trouvés dans {folder_path}\\n\")\n",
    "\n",
    "    for file in files:\n",
    "        print(\"═══════════════════════════════════════════════\")\n",
    "        print(f\"📄 Fichier : {file}\")\n",
    "\n",
    "        # Charger le fichier\n",
    "        df = pd.read_csv(file, sep=sep, encoding=encoding)\n",
    "\n",
    "        # Vérification des colonnes\n",
    "        if value_col not in df.columns or unit_col not in df.columns:\n",
    "            print(f\"⚠️  Fichier ignoré (colonnes manquantes '{value_col}' ou '{unit_col}')\\n\")\n",
    "            continue\n",
    "\n",
    "        # Unité actuelle\n",
    "        current_unit = df[unit_col].iloc[0]\n",
    "        print(f\"🔍 Unité actuelle : {current_unit}\")\n",
    "\n",
    "        # Demander si on veut convertir\n",
    "        resp = input(\"👉 Voulez-vous changer l'unité ? (o/n) : \").strip().lower()\n",
    "        if resp != \"o\":\n",
    "            print(\"➡ Aucun changement pour ce fichier.\\n\")\n",
    "            continue\n",
    "\n",
    "        # Facteur multiplicatif\n",
    "        while True:\n",
    "            try:\n",
    "                factor = float(input(\"➡ Facteur multiplicatif : \"))\n",
    "                break\n",
    "            except ValueError:\n",
    "                print(\"❌ Entrer un nombre valide.\")\n",
    "\n",
    "        # Nouvelle unité\n",
    "        new_unit = input(\"➡ Nouvelle unité : \").strip()\n",
    "        if new_unit == \"\":\n",
    "            print(\"❌ Unité vide — fichier non modifié.\\n\")\n",
    "            continue\n",
    "\n",
    "        # Appliquer la conversion\n",
    "        print(f\"🔄 Conversion : {value_col} × {factor}\")\n",
    "        df[value_col] = df[value_col] * factor\n",
    "        df[unit_col] = new_unit\n",
    "\n",
    "        # Sauvegarder\n",
    "        df.to_csv(file, sep=sep, index=False, encoding=encoding)\n",
    "        print(f\"💾 Fichier mis à jour : {file}\\n\")\n",
    "\n",
    "    print(\"🎉 Conversion terminée pour tous les fichiers.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c90026e6-ecdc-4270-b02b-12ea1d3d035f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 2 fichiers trouvés dans C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\n",
      "\n",
      "═══════════════════════════════════════════════\n",
      "📄 Fichier : C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\Fossil_CO2_emissions_GCB.csv\n",
      "🔍 Unité actuelle : MtC/year\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "👉 Voulez-vous changer l'unité ? (o/n) :  o\n",
      "➡ Facteur multiplicatif :  1000000\n",
      "➡ Nouvelle unité :  tC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Conversion : Value × 1000000.0\n",
      "💾 Fichier mis à jour : C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\Fossil_CO2_emissions_GCB.csv\n",
      "\n",
      "═══════════════════════════════════════════════\n",
      "📄 Fichier : C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\LULUCF_Net_emissions_GCB.csv\n",
      "🔍 Unité actuelle : TgC/year\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "👉 Voulez-vous changer l'unité ? (o/n) :  o\n",
      "➡ Facteur multiplicatif :  tC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Entrer un nombre valide.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "➡ Facteur multiplicatif :  1000000\n",
      "➡ Nouvelle unité :  tC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Conversion : Value × 1000000.0\n",
      "💾 Fichier mis à jour : C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\LULUCF_Net_emissions_GCB.csv\n",
      "\n",
      "🎉 Conversion terminée pour tous les fichiers.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "browse_and_convert_units(base_path, folder_in=\"data_intermediate\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dbf632-09ca-4a6b-95ea-9fda40633636",
   "metadata": {},
   "source": [
    "### CONCAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8f11015-a58b-4c94-be78-cd2a1a4bea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_intermediate_files(base_path, folder_in=\"data_intermediate\", folder_out=\"data_final\", final_filename=\"data_final.csv\", sep=',', encoding='utf-8'):\n",
    "    \"\"\"\n",
    "    Concatène tous les fichiers CSV dans un dossier intermédiaire et sauvegarde le résultat final.\n",
    "    Affiche les fichiers trouvés et le nombre de lignes par fichier.\n",
    "\n",
    "    Paramètres :\n",
    "    - folder_in : dossier contenant les fichiers CSV intermédiaires\n",
    "    - folder_out : dossier où sauvegarder le fichier final\n",
    "    - final_filename : nom du fichier CSV final\n",
    "    - sep : séparateur CSV\n",
    "    - encoding : encodage du fichier\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from pathlib import Path\n",
    "    import glob\n",
    "\n",
    "    # Construire le chemin des fichiers\n",
    "    folder_path = base_path / \"Data\" / folder_in\n",
    "    files = glob.glob(str(folder_path / \"*.csv\"))\n",
    "\n",
    "    if not files:\n",
    "        print(f\"Aucun fichier CSV trouvé dans {folder_path}\")\n",
    "        return None\n",
    "\n",
    "    print(\"Fichiers trouvés et nombre de lignes :\")\n",
    "    dfs = []\n",
    "    for f in files:\n",
    "        df = pd.read_csv(f, sep=sep, encoding=encoding)\n",
    "        print(f\"{f} colonnes : {df.columns.tolist()}\")\n",
    "        print(f\"- {f} : {len(df)} lignes\")\n",
    "        dfs.append(df)\n",
    "\n",
    "    # Concaténer tous les fichiers\n",
    "    df_final = pd.concat(dfs, ignore_index=True)\n",
    "    print(f\"{len(files)} fichiers fusionnés pour obtenir {len(df_final)} lignes au total.\")\n",
    "\n",
    "    # Sauvegarder le résultat final\n",
    "    save_path = base_path / \"Data\" / folder_out / final_filename\n",
    "    save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df_final.to_csv(save_path, sep=sep, index=False, encoding=encoding)\n",
    "\n",
    "    print(f\"DataFrame final sauvegardé dans {save_path}\")\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa68a00-32b4-49fc-9c8c-48c4bf899803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f350ad06-959b-4e03-8b3d-bedfc8bc369b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichiers trouvés et nombre de lignes :\n",
      "C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\Fossil_CO2_emissions_GCB.csv colonnes : ['Year', 'Country', 'Value', 'Unit', 'Indicator', 'Source', 'Country_code']\n",
      "- C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\Fossil_CO2_emissions_GCB.csv : 24636 lignes\n",
      "C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\LULUCF_Net_emissions_GCB.csv colonnes : ['Year', 'Country', 'Value', 'Unit', 'Indicator', 'Source', 'Country_code']\n",
      "- C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\LULUCF_Net_emissions_GCB.csv : 12480 lignes\n",
      "2 fichiers fusionnés pour obtenir 37116 lignes au total.\n",
      "DataFrame final sauvegardé dans C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_final\\data_final_all.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Country</th>\n",
       "      <th>Value</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Indicator</th>\n",
       "      <th>Source</th>\n",
       "      <th>Country_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1949</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>tC</td>\n",
       "      <td>Fossil CO2 emissions</td>\n",
       "      <td>GCB</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1950</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>tC</td>\n",
       "      <td>Fossil CO2 emissions</td>\n",
       "      <td>GCB</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1951</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>tC</td>\n",
       "      <td>Fossil CO2 emissions</td>\n",
       "      <td>GCB</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1952</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>tC</td>\n",
       "      <td>Fossil CO2 emissions</td>\n",
       "      <td>GCB</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1953</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>29000.0</td>\n",
       "      <td>tC</td>\n",
       "      <td>Fossil CO2 emissions</td>\n",
       "      <td>GCB</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year      Country    Value Unit             Indicator Source Country_code\n",
       "0  1949  Afghanistan   4000.0   tC  Fossil CO2 emissions    GCB           AF\n",
       "1  1950  Afghanistan  23000.0   tC  Fossil CO2 emissions    GCB           AF\n",
       "2  1951  Afghanistan  25000.0   tC  Fossil CO2 emissions    GCB           AF\n",
       "3  1952  Afghanistan  25000.0   tC  Fossil CO2 emissions    GCB           AF\n",
       "4  1953  Afghanistan  29000.0   tC  Fossil CO2 emissions    GCB           AF"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concaténer toutes les bases de données dans data_intermediate et enregistrer dans data_final\n",
    "df_final = concat_intermediate_files(\n",
    "    base_path,\n",
    "    folder_in=\"data_intermediate\",\n",
    "    folder_out=\"data_final\",\n",
    "    final_filename=\"data_final_all.csv\"\n",
    ")\n",
    "df_final.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3caaae60-8a2f-4d8d-b29f-f9f1190fa47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_and_add_cumulative(base_path,\n",
    "                              folder_in=\"data_intermediate\",\n",
    "                              folder_out=\"data_final\",\n",
    "                              final_filename=\"data_final.csv\",\n",
    "                              sep=\",\",\n",
    "                              encoding=\"utf-8\",\n",
    "                              group_cols=[\"Country_code\"]):\n",
    "    \"\"\"\n",
    "    Parcourt un dossier contenant des fichiers CSV, ajoute Type='Annual',\n",
    "    puis crée une version Cumulative en cumulant la colonne 'Value' sur 'Year',\n",
    "    en respectant le pays (Code_country).\n",
    "\n",
    "    Paramètres :\n",
    "    - group_cols : colonnes pour grouper les valeurs afin de cumuler (inclut Code_country).\n",
    "    \"\"\"\n",
    "\n",
    "    import pandas as pd\n",
    "    from pathlib import Path\n",
    "    import glob\n",
    "\n",
    "    folder_path = base_path / \"Data\" / folder_in\n",
    "    files = glob.glob(str(folder_path / \"*.csv\"))\n",
    "\n",
    "    if not files:\n",
    "        print(f\"Aucun fichier CSV trouvé dans {folder_path}\")\n",
    "        return None\n",
    "\n",
    "    dfs_all = []\n",
    "\n",
    "    print(\"Fichiers trouvés :\")\n",
    "    for f in files:\n",
    "        print(f\"→ {f}\")\n",
    "\n",
    "        df = pd.read_csv(f, sep=sep, encoding=encoding)\n",
    "\n",
    "        # Vérifications\n",
    "        required_cols = [\"Year\", \"Value\", \"Country_code\"]\n",
    "        for col in required_cols:\n",
    "            if col not in df.columns:\n",
    "                print(f\"⚠️ Fichier ignoré : colonne manquante '{col}' → {f}\")\n",
    "                break\n",
    "        else:\n",
    "            # ANNUAL\n",
    "            df_annual = df.copy()\n",
    "            df_annual[\"Type\"] = \"Annual\"\n",
    "\n",
    "            # CUMULATIVE\n",
    "            df_cum = df.copy()\n",
    "            df_cum[\"Type\"] = \"Cumulative\"\n",
    "\n",
    "            # Cumul par Code_country + autres group_cols\n",
    "            df_cum[\"Value\"] = (\n",
    "                df_cum\n",
    "                .sort_values(\"Year\")\n",
    "                .groupby(group_cols)[\"Value\"]\n",
    "                .cumsum()\n",
    "            )\n",
    "\n",
    "            # Combine Annual + Cumulative\n",
    "            dfs_all.append(pd.concat([df_annual, df_cum], ignore_index=True))\n",
    "\n",
    "    # Fusion de tous les fichiers\n",
    "    df_final = pd.concat(dfs_all, ignore_index=True)\n",
    "\n",
    "    # Sauvegarde\n",
    "    save_path = base_path / \"Data\" / folder_out / final_filename\n",
    "    save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df_final.to_csv(save_path, sep=sep, index=False, encoding=encoding)\n",
    "\n",
    "    print(f\"\\n✔ Données fusionnées et sauvegardées dans : {save_path}\")\n",
    "    print(f\"✔ Total : {len(df_final):,} lignes\")\n",
    "\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e8c94fd3-d746-48fc-b02e-7916f7060ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichiers trouvés :\n",
      "→ C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\Fossil_CO2_emissions_GCB.csv\n",
      "→ C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\LULUCF_Net_emissions_GCB.csv\n",
      "\n",
      "✔ Données fusionnées et sauvegardées dans : C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_final\\data_final_all.csv\n",
      "✔ Total : 74,232 lignes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "df_final=concat_and_add_cumulative(base_path,\n",
    "                              folder_in=\"data_intermediate\",\n",
    "                              folder_out=\"data_final\",\n",
    "                              final_filename=\"data_final_all.csv\",\n",
    "                              sep=\",\",\n",
    "                              encoding=\"utf-8\",\n",
    "                              group_cols=[\"Country_code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f82cbf50-a98d-4619-80f7-4b68c0b19456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\Fossil_CO2_emissions_GCB.csv\n",
      "File loaded: C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\Fossil_CO2_emissions_GCB.csv\n",
      "------------------------------------------------------------\n",
      "Countries missing Country_code:\n",
      " - Namibia\n",
      "\n",
      "Please enter the missing Country_code values.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Country_code for 'Namibia':  NAM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated file saved!\n",
      " → C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\Fossil_CO2_emissions_GCB.csv\n",
      "Loading data from: C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\LULUCF_Net_emissions_GCB.csv\n",
      "File loaded: C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\LULUCF_Net_emissions_GCB.csv\n",
      "------------------------------------------------------------\n",
      "Countries missing Country_code:\n",
      " - Namibia\n",
      "\n",
      "Please enter the missing Country_code values.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Country_code for 'Namibia':  NAM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated file saved!\n",
      " → C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\LULUCF_Net_emissions_GCB.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "folder = base_path / 'Data' / 'data_intermediate'\n",
    "\n",
    "# Loop over all files in the folder (e.g., CSV files)\n",
    "for filepath in folder.glob('*.csv'):  # adjust pattern if needed\n",
    "     # read the file\n",
    "    df_fixed = fix_missing_country_codes(filepath)  # apply your function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fd3b0a-faf3-4bac-82f6-7f5a2fa8dcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHECK NO COUNTRY CODE BUT DATA AND UPDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d0737ea7-cb9f-4c61-96b3-d1c9e3a3cfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def import_csv_data(filepath):\n",
    "    print(\"Loading data from:\", filepath.resolve())  # debug\n",
    "    df = pd.read_csv(filepath)\n",
    "    return df\n",
    "    \n",
    "def fix_missing_country_codes(filepath, country_col=\"Country\", code_col=\"Country_code\"):\n",
    "    \"\"\"\n",
    "    Load a file, detect countries missing country_code, ask user for the code,\n",
    "    update the file, and save the corrected version.\n",
    "    \"\"\"\n",
    "    # Load file\n",
    "    df = import_csv_data(filepath)\n",
    "    print(f\"File loaded: {filepath}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # Identify missing codes\n",
    "    missing_mask = df[code_col].isna() | (df[code_col].astype(str).str.strip() == \"\")\n",
    "    missing_countries = df.loc[missing_mask, country_col].unique()\n",
    "\n",
    "    if len(missing_countries) == 0:\n",
    "        print(\"No missing Country_code found. Nothing to fix.\")\n",
    "        return df\n",
    "\n",
    "    print(\"Countries missing Country_code:\")\n",
    "    for c in missing_countries:\n",
    "        print(f\" - {c}\")\n",
    "\n",
    "    print(\"\\nPlease enter the missing Country_code values.\\n\")\n",
    "\n",
    "    # Ask manually for each missing country\n",
    "    replacement_map = {}\n",
    "    for country in missing_countries:\n",
    "        code = input(f\"Enter Country_code for '{country}': \").strip()\n",
    "        replacement_map[country] = code\n",
    "\n",
    "    # Apply replacements\n",
    "    for country, code in replacement_map.items():\n",
    "        df.loc[df[country_col] == country, code_col] = code\n",
    "\n",
    "    # Save file (overwrite)\n",
    "    df.to_csv(filepath, index=False)\n",
    "    print(\"\\nUpdated file saved!\")\n",
    "    print(f\" → {filepath}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a6e4796-9273-47ca-a6e2-7bdaeb3f2581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_final\\data_final_all_norm.csv\n",
      "File loaded: C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_final\\data_final_all_norm.csv\n",
      "------------------------------------------------------------\n",
      "No missing Country_code found. Nothing to fix.\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
