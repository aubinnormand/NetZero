{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "18cd5740-c40d-4e30-b029-4506e57bc221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "import ipynbname \n",
    "import pandas as pd\n",
    "\n",
    "code_path = ipynbname.path().parent.parent\n",
    "# Ajouter le dossier scripts au path\n",
    "scripts_path = code_path  / \"scripts\"\n",
    "sys.path.append(str(scripts_path.resolve()))\n",
    "\n",
    "import data_utils  # importe le module une premi√®re fois\n",
    "\n",
    "# Apr√®s avoir modifi√© data_utils.py\n",
    "importlib.reload(data_utils)\n",
    "\n",
    "base_path = code_path.parent\n",
    "# Maintenant tu peux acc√©der aux fonctions mises √† jour\n",
    "from data_utils import import_data_raw, import_data_sig, melt_long_format, clean_year_column, save_long_dataframe, concat_intermediate_files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26406ff-a1f0-4ed3-aeb8-129d900d2ebc",
   "metadata": {},
   "source": [
    "## Importation et formatage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9b1f8c37-4003-4114-bb80-72d6f462f0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Afghanistan</th>\n",
       "      <th>Albania</th>\n",
       "      <th>Algeria</th>\n",
       "      <th>Andorra</th>\n",
       "      <th>Angola</th>\n",
       "      <th>Anguilla</th>\n",
       "      <th>Antigua and Barbuda</th>\n",
       "      <th>Argentina</th>\n",
       "      <th>Armenia</th>\n",
       "      <th>...</th>\n",
       "      <th>Uruguay</th>\n",
       "      <th>Uzbekistan</th>\n",
       "      <th>Vanuatu</th>\n",
       "      <th>Venezuela</th>\n",
       "      <th>Vietnam</th>\n",
       "      <th>Wallis and Futuna Islands</th>\n",
       "      <th>Western Sahara</th>\n",
       "      <th>Yemen</th>\n",
       "      <th>Zambia</th>\n",
       "      <th>Zimbabwe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1963</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1964</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 222 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0 Afghanistan Albania Algeria Andorra Angola Anguilla  \\\n",
       "0       1960         NaN     NaN     NaN     NaN    NaN      NaN   \n",
       "1       1961         NaN     NaN     NaN     NaN    NaN      NaN   \n",
       "2       1962         NaN     NaN     NaN     NaN    NaN      NaN   \n",
       "3       1963         NaN     NaN     NaN     NaN    NaN      NaN   \n",
       "4       1964         NaN     NaN     NaN     NaN    NaN      NaN   \n",
       "\n",
       "  Antigua and Barbuda Argentina Armenia  ... Uruguay Uzbekistan Vanuatu  \\\n",
       "0                 NaN       NaN     NaN  ...     NaN        NaN     NaN   \n",
       "1                 NaN       NaN     NaN  ...     NaN        NaN     NaN   \n",
       "2                 NaN       NaN     NaN  ...     NaN        NaN     NaN   \n",
       "3                 NaN       NaN     NaN  ...     NaN        NaN     NaN   \n",
       "4                 NaN       NaN     NaN  ...     NaN        NaN     NaN   \n",
       "\n",
       "  Venezuela Vietnam Wallis and Futuna Islands Western Sahara Yemen Zambia  \\\n",
       "0       NaN     NaN                       NaN            NaN   NaN    NaN   \n",
       "1       NaN     NaN                       NaN            NaN   NaN    NaN   \n",
       "2       NaN     NaN                       NaN            NaN   NaN    NaN   \n",
       "3       NaN     NaN                       NaN            NaN   NaN    NaN   \n",
       "4       NaN     NaN                       NaN            NaN   NaN    NaN   \n",
       "\n",
       "  Zimbabwe  \n",
       "0      NaN  \n",
       "1      NaN  \n",
       "2      NaN  \n",
       "3      NaN  \n",
       "4      NaN  \n",
       "\n",
       "[5 rows x 222 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualisation du fichier\n",
    "filename=\"GCB_FFConsumption_Countries.csv\"\n",
    "filepath= base_path/ \"Data\" / 'data_raw' / filename\n",
    "\n",
    "df = pd.read_csv(filepath, dtype=str,header=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0bb3dafd-b58b-4a4d-b4d3-6547e79a11af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feuilles dans le fichier : ['Summary', 'Territorial Emissions', 'Consumption Emissions', 'Emissions Transfers', 'Regions']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Afghanistan</th>\n",
       "      <th>Albania</th>\n",
       "      <th>Algeria</th>\n",
       "      <th>Andorra</th>\n",
       "      <th>Angola</th>\n",
       "      <th>Anguilla</th>\n",
       "      <th>Antigua and Barbuda</th>\n",
       "      <th>Argentina</th>\n",
       "      <th>Armenia</th>\n",
       "      <th>...</th>\n",
       "      <th>Asia</th>\n",
       "      <th>Central America</th>\n",
       "      <th>Europe</th>\n",
       "      <th>Middle East</th>\n",
       "      <th>North America</th>\n",
       "      <th>Oceania</th>\n",
       "      <th>South America</th>\n",
       "      <th>Bunkers</th>\n",
       "      <th>Statistical Difference</th>\n",
       "      <th>World</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.8521138750599e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00401202150994847</td>\n",
       "      <td>0</td>\n",
       "      <td>48.2464969314514</td>\n",
       "      <td>0</td>\n",
       "      <td>5.418</td>\n",
       "      <td>0.0305820009434216</td>\n",
       "      <td>0.0256893</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.4210854715202e-14</td>\n",
       "      <td>53.7247802539048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.45060918332</td>\n",
       "      <td>0</td>\n",
       "      <td>6.742</td>\n",
       "      <td>0.0290334908417313</td>\n",
       "      <td>0.0301441</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.105427357601e-15</td>\n",
       "      <td>54.2517867741618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49.24473830895</td>\n",
       "      <td>0</td>\n",
       "      <td>7.335</td>\n",
       "      <td>0.0289450290888339</td>\n",
       "      <td>0.0493654</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.6580487380389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.9561893611538</td>\n",
       "      <td>0</td>\n",
       "      <td>8.26</td>\n",
       "      <td>0.0415723001759676</td>\n",
       "      <td>0.0318038</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.105427357601e-15</td>\n",
       "      <td>59.2895654613298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1854</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60.4710333066774</td>\n",
       "      <td>0</td>\n",
       "      <td>9.084</td>\n",
       "      <td>0.0500891057352644</td>\n",
       "      <td>0.0014707</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4210854715202e-14</td>\n",
       "      <td>69.6065931124127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000207773775566332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121654845785534</td>\n",
       "      <td>0</td>\n",
       "      <td>60.4634048089304</td>\n",
       "      <td>0</td>\n",
       "      <td>10.456</td>\n",
       "      <td>0.0588639963115096</td>\n",
       "      <td>0.0411845</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.4210854715202e-14</td>\n",
       "      <td>71.0316187898205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1856</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0045444</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1049454</td>\n",
       "      <td>64.6237705939835</td>\n",
       "      <td>0</td>\n",
       "      <td>10.9781749</td>\n",
       "      <td>0.0815737600990279</td>\n",
       "      <td>0.1519357</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75.9404003540825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0111237</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0984529</td>\n",
       "      <td>65.0462936367495</td>\n",
       "      <td>0</td>\n",
       "      <td>11.2659992</td>\n",
       "      <td>0.0903658277146707</td>\n",
       "      <td>0.2404409</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.4210854715202e-14</td>\n",
       "      <td>76.7415524644642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1858</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0144018</td>\n",
       "      <td>0.000291767429518679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124749367485013</td>\n",
       "      <td>0.0923615</td>\n",
       "      <td>65.9174383789256</td>\n",
       "      <td>0</td>\n",
       "      <td>11.4432252</td>\n",
       "      <td>0.0929264948628625</td>\n",
       "      <td>0.2628115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77.9335124412735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1859</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0092316</td>\n",
       "      <td>0.000309450304034963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191831889530606</td>\n",
       "      <td>0.0866474</td>\n",
       "      <td>69.5046705677605</td>\n",
       "      <td>0</td>\n",
       "      <td>12.4571777</td>\n",
       "      <td>0.132354671096029</td>\n",
       "      <td>0.20706</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82.5797422283872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows √ó 231 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year Afghanistan Albania Algeria Andorra Angola Anguilla  \\\n",
       "0  1850         NaN     NaN     NaN     NaN    NaN      NaN   \n",
       "1  1851         NaN     NaN     NaN     NaN    NaN      NaN   \n",
       "2  1852         NaN     NaN     NaN     NaN    NaN      NaN   \n",
       "3  1853         NaN     NaN     NaN     NaN    NaN      NaN   \n",
       "4  1854         NaN     NaN     NaN     NaN    NaN      NaN   \n",
       "5  1855         NaN     NaN     NaN     NaN    NaN      NaN   \n",
       "6  1856         NaN     NaN     NaN     NaN    NaN      NaN   \n",
       "7  1857         NaN     NaN     NaN     NaN    NaN      NaN   \n",
       "8  1858         NaN     NaN     NaN     NaN    NaN      NaN   \n",
       "9  1859         NaN     NaN     NaN     NaN    NaN      NaN   \n",
       "\n",
       "  Antigua and Barbuda  Argentina               Armenia  ...  \\\n",
       "0                   0        NaN   6.8521138750599e-05  ...   \n",
       "1                   0        NaN                     0  ...   \n",
       "2                   0        NaN                     0  ...   \n",
       "3                   0        NaN                     0  ...   \n",
       "4                   0        NaN                     0  ...   \n",
       "5                   0        NaN  0.000207773775566332  ...   \n",
       "6                   0  0.0045444                     0  ...   \n",
       "7                   0  0.0111237                     0  ...   \n",
       "8                   0  0.0144018  0.000291767429518679  ...   \n",
       "9                   0  0.0092316  0.000309450304034963  ...   \n",
       "\n",
       "                  Asia Central America            Europe Middle East  \\\n",
       "0  0.00401202150994847               0  48.2464969314514           0   \n",
       "1                    0               0    47.45060918332           0   \n",
       "2                    0               0    49.24473830895           0   \n",
       "3                    0               0  50.9561893611538           0   \n",
       "4                    0               0  60.4710333066774           0   \n",
       "5   0.0121654845785534               0  60.4634048089304           0   \n",
       "6                    0       0.1049454  64.6237705939835           0   \n",
       "7                    0       0.0984529  65.0462936367495           0   \n",
       "8    0.124749367485013       0.0923615  65.9174383789256           0   \n",
       "9    0.191831889530606       0.0866474  69.5046705677605           0   \n",
       "\n",
       "  North America             Oceania South America Bunkers  \\\n",
       "0         5.418  0.0305820009434216     0.0256893       0   \n",
       "1         6.742  0.0290334908417313     0.0301441       0   \n",
       "2         7.335  0.0289450290888339     0.0493654       0   \n",
       "3          8.26  0.0415723001759676     0.0318038       0   \n",
       "4         9.084  0.0500891057352644     0.0014707       0   \n",
       "5        10.456  0.0588639963115096     0.0411845       0   \n",
       "6    10.9781749  0.0815737600990279     0.1519357       0   \n",
       "7    11.2659992  0.0903658277146707     0.2404409       0   \n",
       "8    11.4432252  0.0929264948628625     0.2628115       0   \n",
       "9    12.4571777   0.132354671096029       0.20706       0   \n",
       "\n",
       "  Statistical Difference             World  \n",
       "0   -1.4210854715202e-14  53.7247802539048  \n",
       "1    -7.105427357601e-15  54.2517867741618  \n",
       "2                      0  56.6580487380389  \n",
       "3    -7.105427357601e-15  59.2895654613298  \n",
       "4    1.4210854715202e-14  69.6065931124127  \n",
       "5   -1.4210854715202e-14  71.0316187898205  \n",
       "6                      0  75.9404003540825  \n",
       "7   -1.4210854715202e-14  76.7415524644642  \n",
       "8                      0  77.9335124412735  \n",
       "9                      0  82.5797422283872  \n",
       "\n",
       "[10 rows x 231 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# D√©finir le chemin\n",
    "filename = \"National_Fossil_Carbon_Emissions_2024v1.0-1.xlsx\"\n",
    "filepath = base_path / \"Data\" / 'GHG Datasets' / 'Global Carbon Budget' / filename\n",
    "\n",
    "# Charger le fichier Excel\n",
    "xls = pd.ExcelFile(filepath)\n",
    "\n",
    "# Afficher les noms des feuilles\n",
    "print(\"Feuilles dans le fichier :\", xls.sheet_names)\n",
    "\n",
    "# Lire la feuille souhait√©e\n",
    "df = pd.read_excel(filepath, sheet_name=xls.sheet_names[1], dtype=str, header=11)\n",
    "\n",
    "# Renommer la premi√®re colonne en 'Year'\n",
    "df.rename(columns={df.columns[0]: \"Year\"}, inplace=True)\n",
    "\n",
    "# V√©rifier\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d1c2168d-f75a-4911-adab-da05509036f8",
   "metadata": {},
   "source": [
    "#Importation\n",
    "df = import_data_raw(filepath, n_header=1, sheet_name=xls.sheet_names[1])\n",
    "df = clean_year_column(df)  # nettoie la colonne Year\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "45c5367f-e7e6-4dc4-8656-eaaccb43434a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Country</th>\n",
       "      <th>Value</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Indicator</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1850</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tC</td>\n",
       "      <td>Fossil Fuel Consumption</td>\n",
       "      <td>GCB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1851</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tC</td>\n",
       "      <td>Fossil Fuel Consumption</td>\n",
       "      <td>GCB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1852</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tC</td>\n",
       "      <td>Fossil Fuel Consumption</td>\n",
       "      <td>GCB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1853</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tC</td>\n",
       "      <td>Fossil Fuel Consumption</td>\n",
       "      <td>GCB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1854</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tC</td>\n",
       "      <td>Fossil Fuel Consumption</td>\n",
       "      <td>GCB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year      Country  Value Unit                Indicator Source\n",
       "0  1850  Afghanistan    NaN   tC  Fossil Fuel Consumption    GCB\n",
       "1  1851  Afghanistan    NaN   tC  Fossil Fuel Consumption    GCB\n",
       "2  1852  Afghanistan    NaN   tC  Fossil Fuel Consumption    GCB\n",
       "3  1853  Afghanistan    NaN   tC  Fossil Fuel Consumption    GCB\n",
       "4  1854  Afghanistan    NaN   tC  Fossil Fuel Consumption    GCB"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Passage en format long\n",
    "source=\"GCB\"\n",
    "unit=\"tC\" \n",
    "facteur_conversion=1e6*0.272727  #3.66666 from C to C02, 0.272727 from CO2 to C \n",
    "indicator=\"Fossil Fuel Consumption\"\n",
    "df_long = melt_long_format(df, id_vars=['Year'], var_name='Country', value_name='Value', source=source,unit=unit, indicator=indicator)\n",
    "\n",
    "df_long[\"Value\"] = pd.to_numeric(df_long[\"Value\"], errors=\"coerce\") * facteur_conversion\n",
    "\n",
    "\n",
    "df_long.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd2e71f-8cc5-4b81-bc20-115c160941ff",
   "metadata": {},
   "source": [
    "## SIG ET NOM DE PAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd0f0a95-4c40-4d75-bb8f-90d1d9b45a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_point_2d</th>\n",
       "      <th>iso3</th>\n",
       "      <th>status</th>\n",
       "      <th>color_code</th>\n",
       "      <th>name</th>\n",
       "      <th>continent</th>\n",
       "      <th>region</th>\n",
       "      <th>iso_3166_1_alpha_2_codes</th>\n",
       "      <th>french_short</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{ \"lon\": -16.984917430414384, \"lat\": 32.747916...</td>\n",
       "      <td>None</td>\n",
       "      <td>PT Territory</td>\n",
       "      <td>PRT</td>\n",
       "      <td>Madeira Islands</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Southern Europe</td>\n",
       "      <td>None</td>\n",
       "      <td>Madeira Islands</td>\n",
       "      <td>POLYGON ((-17.1025 32.82333, -17.05306 32.8094...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{ \"lon\": 33.743791080217562, \"lat\": 21.8927401...</td>\n",
       "      <td>None</td>\n",
       "      <td>Adm. by EGY</td>\n",
       "      <td>EGY</td>\n",
       "      <td>Ma'tan al-Sarra</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Northern Africa</td>\n",
       "      <td>None</td>\n",
       "      <td>Ma'tan al-Sarra</td>\n",
       "      <td>POLYGON ((33.25104 21.99977, 34.15064 21.99603...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{ \"lon\": 9.5613358449883421, \"lat\": 34.1108585...</td>\n",
       "      <td>TUN</td>\n",
       "      <td>Member State</td>\n",
       "      <td>TUN</td>\n",
       "      <td>Tunisia</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Northern Africa</td>\n",
       "      <td>TN</td>\n",
       "      <td>Tunisie</td>\n",
       "      <td>MULTIPOLYGON (((10.99361 33.75, 10.93778 33.72...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{ \"lon\": 43.77213543247138, \"lat\": 33.04802449...</td>\n",
       "      <td>IRQ</td>\n",
       "      <td>Member State</td>\n",
       "      <td>IRQ</td>\n",
       "      <td>Iraq</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Western Asia</td>\n",
       "      <td>IQ</td>\n",
       "      <td>Iraq</td>\n",
       "      <td>POLYGON ((44.78734 37.14971, 44.76617 37.11228...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{ \"lon\": -6.3178452255610269, \"lat\": 31.883624...</td>\n",
       "      <td>MAR</td>\n",
       "      <td>Member State</td>\n",
       "      <td>MAR</td>\n",
       "      <td>Morocco</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Northern Africa</td>\n",
       "      <td>MA</td>\n",
       "      <td>Maroc</td>\n",
       "      <td>POLYGON ((-2.94694 35.32916, -2.96618 35.31663...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        geo_point_2d  iso3        status  \\\n",
       "0  { \"lon\": -16.984917430414384, \"lat\": 32.747916...  None  PT Territory   \n",
       "1  { \"lon\": 33.743791080217562, \"lat\": 21.8927401...  None   Adm. by EGY   \n",
       "2  { \"lon\": 9.5613358449883421, \"lat\": 34.1108585...   TUN  Member State   \n",
       "3  { \"lon\": 43.77213543247138, \"lat\": 33.04802449...   IRQ  Member State   \n",
       "4  { \"lon\": -6.3178452255610269, \"lat\": 31.883624...   MAR  Member State   \n",
       "\n",
       "  color_code             name continent           region  \\\n",
       "0        PRT  Madeira Islands    Europe  Southern Europe   \n",
       "1        EGY  Ma'tan al-Sarra    Africa  Northern Africa   \n",
       "2        TUN          Tunisia    Africa  Northern Africa   \n",
       "3        IRQ             Iraq      Asia     Western Asia   \n",
       "4        MAR          Morocco    Africa  Northern Africa   \n",
       "\n",
       "  iso_3166_1_alpha_2_codes     french_short  \\\n",
       "0                     None  Madeira Islands   \n",
       "1                     None  Ma'tan al-Sarra   \n",
       "2                       TN          Tunisie   \n",
       "3                       IQ             Iraq   \n",
       "4                       MA            Maroc   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((-17.1025 32.82333, -17.05306 32.8094...  \n",
       "1  POLYGON ((33.25104 21.99977, 34.15064 21.99603...  \n",
       "2  MULTIPOLYGON (((10.99361 33.75, 10.93778 33.72...  \n",
       "3  POLYGON ((44.78734 37.14971, 44.76617 37.11228...  \n",
       "4  POLYGON ((-2.94694 35.32916, -2.96618 35.31663...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importation de fichier SIG\n",
    "gdf_world=import_data_sig(base_path,'world-administrative-boundaries.geojson')\n",
    "#gdf_world[['iso_3166_1_alpha_2_codes', 'name']]\n",
    "\n",
    "gdf_world.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5133f651-8cf7-4dee-881a-2c034cc8c84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_point_2d</th>\n",
       "      <th>iso3</th>\n",
       "      <th>status</th>\n",
       "      <th>color_code</th>\n",
       "      <th>name</th>\n",
       "      <th>continent</th>\n",
       "      <th>region</th>\n",
       "      <th>Country_code</th>\n",
       "      <th>french_short</th>\n",
       "      <th>Country</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{ \"lon\": -16.984917430414384, \"lat\": 32.747916...</td>\n",
       "      <td>None</td>\n",
       "      <td>PT Territory</td>\n",
       "      <td>PRT</td>\n",
       "      <td>Madeira Islands</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Southern Europe</td>\n",
       "      <td>None</td>\n",
       "      <td>Madeira Islands</td>\n",
       "      <td>None</td>\n",
       "      <td>POLYGON ((-17.1025 32.82333, -17.05306 32.8094...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{ \"lon\": 33.743791080217562, \"lat\": 21.8927401...</td>\n",
       "      <td>None</td>\n",
       "      <td>Adm. by EGY</td>\n",
       "      <td>EGY</td>\n",
       "      <td>Ma'tan al-Sarra</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Northern Africa</td>\n",
       "      <td>None</td>\n",
       "      <td>Ma'tan al-Sarra</td>\n",
       "      <td>None</td>\n",
       "      <td>POLYGON ((33.25104 21.99977, 34.15064 21.99603...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{ \"lon\": 9.5613358449883421, \"lat\": 34.1108585...</td>\n",
       "      <td>TUN</td>\n",
       "      <td>Member State</td>\n",
       "      <td>TUN</td>\n",
       "      <td>Tunisia</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Northern Africa</td>\n",
       "      <td>TN</td>\n",
       "      <td>Tunisie</td>\n",
       "      <td>Tunisia</td>\n",
       "      <td>MULTIPOLYGON (((10.99361 33.75, 10.93778 33.72...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{ \"lon\": 43.77213543247138, \"lat\": 33.04802449...</td>\n",
       "      <td>IRQ</td>\n",
       "      <td>Member State</td>\n",
       "      <td>IRQ</td>\n",
       "      <td>Iraq</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Western Asia</td>\n",
       "      <td>IQ</td>\n",
       "      <td>Iraq</td>\n",
       "      <td>Iraq</td>\n",
       "      <td>POLYGON ((44.78734 37.14971, 44.76617 37.11228...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{ \"lon\": -6.3178452255610269, \"lat\": 31.883624...</td>\n",
       "      <td>MAR</td>\n",
       "      <td>Member State</td>\n",
       "      <td>MAR</td>\n",
       "      <td>Morocco</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Northern Africa</td>\n",
       "      <td>MA</td>\n",
       "      <td>Maroc</td>\n",
       "      <td>Morocco</td>\n",
       "      <td>POLYGON ((-2.94694 35.32916, -2.96618 35.31663...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        geo_point_2d  iso3        status  \\\n",
       "0  { \"lon\": -16.984917430414384, \"lat\": 32.747916...  None  PT Territory   \n",
       "1  { \"lon\": 33.743791080217562, \"lat\": 21.8927401...  None   Adm. by EGY   \n",
       "2  { \"lon\": 9.5613358449883421, \"lat\": 34.1108585...   TUN  Member State   \n",
       "3  { \"lon\": 43.77213543247138, \"lat\": 33.04802449...   IRQ  Member State   \n",
       "4  { \"lon\": -6.3178452255610269, \"lat\": 31.883624...   MAR  Member State   \n",
       "\n",
       "  color_code             name continent           region Country_code  \\\n",
       "0        PRT  Madeira Islands    Europe  Southern Europe         None   \n",
       "1        EGY  Ma'tan al-Sarra    Africa  Northern Africa         None   \n",
       "2        TUN          Tunisia    Africa  Northern Africa           TN   \n",
       "3        IRQ             Iraq      Asia     Western Asia           IQ   \n",
       "4        MAR          Morocco    Africa  Northern Africa           MA   \n",
       "\n",
       "      french_short  Country                                           geometry  \n",
       "0  Madeira Islands     None  POLYGON ((-17.1025 32.82333, -17.05306 32.8094...  \n",
       "1  Ma'tan al-Sarra     None  POLYGON ((33.25104 21.99977, 34.15064 21.99603...  \n",
       "2          Tunisie  Tunisia  MULTIPOLYGON (((10.99361 33.75, 10.93778 33.72...  \n",
       "3             Iraq     Iraq  POLYGON ((44.78734 37.14971, 44.76617 37.11228...  \n",
       "4            Maroc  Morocco  POLYGON ((-2.94694 35.32916, -2.96618 35.31663...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importation de fichier SIG\n",
    "gdf_world=import_data_sig(base_path,'world.geojson')\n",
    "#gdf_world[['iso_3166_1_alpha_2_codes', 'name']]\n",
    "\n",
    "gdf_world.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcba416f-aa57-4be4-bb6e-5316562e46bd",
   "metadata": {},
   "source": [
    "### OPTIONAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6acfdae6-fdca-47b2-ad69-7a428d7ebbb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['iso_3166_1_alpha_2_codes'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[62]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Fusion des deux tables\u001b[39;00m\n\u001b[32m      4\u001b[39m df_merged = df_long.merge(\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[43mgdf_world\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43miso_3166_1_alpha_2_codes\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mname\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[32m      6\u001b[39m     left_on=\u001b[33m'\u001b[39m\u001b[33mCountry\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      7\u001b[39m     right_on=\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      8\u001b[39m     how=\u001b[33m'\u001b[39m\u001b[33mouter\u001b[39m\u001b[33m'\u001b[39m,  \u001b[38;5;66;03m# on garde tout pour pouvoir identifier les non-correspondances\u001b[39;00m\n\u001b[32m      9\u001b[39m     indicator=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     10\u001b[39m )\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# --- Identifier les correspondances et les non-correspondances ---\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Country sans √©quivalent dans gdf_world['name']\u001b[39;00m\n\u001b[32m     14\u001b[39m country_sans_name = df_merged[df_merged[\u001b[33m'\u001b[39m\u001b[33m_merge\u001b[39m\u001b[33m'\u001b[39m] == \u001b[33m'\u001b[39m\u001b[33mleft_only\u001b[39m\u001b[33m'\u001b[39m][[\u001b[33m'\u001b[39m\u001b[33mCountry\u001b[39m\u001b[33m'\u001b[39m]].drop_duplicates()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\geopandas\\geodataframe.py:1896\u001b[39m, in \u001b[36mGeoDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[32m   1891\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1892\u001b[39m \u001b[33;03m    If the result is a column containing only 'geometry', return a\u001b[39;00m\n\u001b[32m   1893\u001b[39m \u001b[33;03m    GeoSeries. If it's a DataFrame with any columns of GeometryDtype,\u001b[39;00m\n\u001b[32m   1894\u001b[39m \u001b[33;03m    return a GeoDataFrame.\u001b[39;00m\n\u001b[32m   1895\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1896\u001b[39m     result = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1897\u001b[39m     \u001b[38;5;66;03m# Custom logic to avoid waiting for pandas GH51895\u001b[39;00m\n\u001b[32m   1898\u001b[39m     \u001b[38;5;66;03m# result is not geometry dtype for multi-indexes\u001b[39;00m\n\u001b[32m   1899\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1900\u001b[39m         pd.api.types.is_scalar(key)\n\u001b[32m   1901\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m key == \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1904\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_geometry_type(result)\n\u001b[32m   1905\u001b[39m     ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4119\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4118\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4119\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4121\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['iso_3166_1_alpha_2_codes'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Fusion des deux tables\n",
    "df_merged = df_long.merge(\n",
    "    gdf_world[['iso_3166_1_alpha_2_codes', 'name']],\n",
    "    left_on='Country',\n",
    "    right_on='name',\n",
    "    how='outer',  # on garde tout pour pouvoir identifier les non-correspondances\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# --- Identifier les correspondances et les non-correspondances ---\n",
    "# Country sans √©quivalent dans gdf_world['name']\n",
    "country_sans_name = df_merged[df_merged['_merge'] == 'left_only'][['Country']].drop_duplicates()\n",
    "\n",
    "# name sans √©quivalent dans df_final['Country']\n",
    "name_sans_country = df_merged[df_merged['_merge'] == 'right_only'][['name']].drop_duplicates()\n",
    "\n",
    "# Comptage\n",
    "print(f\"Nombre de 'Country' sans √©quivalent : {len(country_sans_name)}\")\n",
    "print(f\"Nombre de 'name' sans √©quivalent : {len(name_sans_country)}\")\n",
    "\n",
    "# Optionnel : garder seulement les ligne\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "83827734-b321-4491-bddf-435781667817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üåç Nom : Netherlands Antilles (FR : Netherlands Antilles)\n",
      "‚Üí Correspondances par inclusion :\n",
      "  [0] Netherlands\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "S√©lectionner le num√©ro de la correspondance √† valider (Entr√©e pour ignorer) :  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Aucune correspondance valid√©e pour Netherlands Antilles\n",
      "\n",
      "üåç Nom : British Indian Ocean Territory (FR : British Indian Ocean Territory)\n",
      "‚Üí Correspondances par inclusion :\n",
      "  [0] India\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "S√©lectionner le num√©ro de la correspondance √† valider (Entr√©e pour ignorer) :  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Aucune correspondance valid√©e pour British Indian Ocean Territory\n",
      "\n",
      "üåç Nom : Antigua & Barbuda (FR : Antigua-et-Barbuda)\n",
      "‚Üí Correspondances floues potentielles dans df_merged['Country'] :\n",
      "  [0] Antigua and Barbuda\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "S√©lectionner le num√©ro de la correspondance √† valider (Entr√©e pour ignorer) :  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Correspondance valid√©e (floue) : Antigua & Barbuda ‚Üí Antigua and Barbuda\n",
      "\n",
      "üåç Nom : United Republic of Tanzania (FR : R√©publique-Unie de Tanzanie)\n",
      "‚Üí Correspondances par inclusion :\n",
      "  [0] Tanzania\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "S√©lectionner le num√©ro de la correspondance √† valider (Entr√©e pour ignorer) :  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Correspondance valid√©e (inclusion) : United Republic of Tanzania ‚Üí Tanzania\n",
      "\n",
      "üåç Nom : Moldova, Republic of (FR : R√©publique de Moldova)\n",
      "‚Üí Correspondances par inclusion :\n",
      "  [0] Moldova\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "S√©lectionner le num√©ro de la correspondance √† valider (Entr√©e pour ignorer) :  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Correspondance valid√©e (inclusion) : Moldova, Republic of ‚Üí Moldova\n",
      "\n",
      "üåç Nom : Syrian Arab Republic (FR : R√©publique arabe syrienne)\n",
      "‚Üí Correspondances par inclusion :\n",
      "  [0] Syria\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "S√©lectionner le num√©ro de la correspondance √† valider (Entr√©e pour ignorer) :  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Correspondance valid√©e (inclusion) : Syrian Arab Republic ‚Üí Syria\n",
      "\n",
      "üåç Nom : Libyan Arab Jamahiriya (FR : Libye)\n",
      "‚Üí Correspondances par inclusion :\n",
      "  [0] Libya\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "S√©lectionner le num√©ro de la correspondance √† valider (Entr√©e pour ignorer) :  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Correspondance valid√©e (inclusion) : Libyan Arab Jamahiriya ‚Üí Libya\n",
      "\n",
      "üåç Nom : U.K. of Great Britain and Northern Ireland (FR : Royaume-Uni de Grande-Bretagne et d'Irlande du Nord)\n",
      "‚Üí Correspondances par inclusion :\n",
      "  [0] Ireland\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "S√©lectionner le num√©ro de la correspondance √† valider (Entr√©e pour ignorer) :  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Aucune correspondance valid√©e pour U.K. of Great Britain and Northern Ireland\n",
      "\n",
      "üåç Nom : South Sudan (FR : Soudan du Sud)\n",
      "‚Üí Correspondances par inclusion :\n",
      "  [0] Republic of South Sudan\n",
      "  [1] Sudan\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "S√©lectionner le num√©ro de la correspondance √† valider (Entr√©e pour ignorer) :  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Correspondance valid√©e (inclusion) : South Sudan ‚Üí Republic of South Sudan\n",
      "\n",
      "üåç Nom : American Samoa (FR : American Samoa)\n",
      "‚Üí Correspondances par inclusion :\n",
      "  [0] Samoa\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "S√©lectionner le num√©ro de la correspondance √† valider (Entr√©e pour ignorer) :  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Aucune correspondance valid√©e pour American Samoa\n",
      "\n",
      "üåç Nom : South Georgia & the South Sandwich Islands (FR : South Georgia & the South Sandwich Islands)\n",
      "‚Üí Correspondances par inclusion :\n",
      "  [0] Georgia\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "S√©lectionner le num√©ro de la correspondance √† valider (Entr√©e pour ignorer) :  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Aucune correspondance valid√©e pour South Georgia & the South Sandwich Islands\n",
      "\n",
      "üåç Nom : Bosnia & Herzegovina (FR : Bosnie-Herz√©govine)\n",
      "‚Üí Correspondances floues potentielles dans df_merged['Country'] :\n",
      "  [0] Bosnia and Herzegovina\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "S√©lectionner le num√©ro de la correspondance √† valider (Entr√©e pour ignorer) :  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Correspondance valid√©e (floue) : Bosnia & Herzegovina ‚Üí Bosnia and Herzegovina\n",
      "\n",
      "‚úÖ Mise √† jour termin√©e.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from difflib import get_close_matches\n",
    "\n",
    "# --- Pr√©paration ---\n",
    "countries = df_long['Country'].dropna().unique()\n",
    "gdf_world['Country'] = None  # colonne √† cr√©er/remplir\n",
    "\n",
    "from difflib import get_close_matches\n",
    "\n",
    "# --- Fonction utilitaire pour trouver les meilleures correspondances ---\n",
    "def find_best_match(target, candidates, cutoff=0.8):\n",
    "    \"\"\"Retourne les meilleures correspondances au-dessus du seuil de similarit√©.\"\"\"\n",
    "    return get_close_matches(target, candidates, n=5, cutoff=cutoff)\n",
    "\n",
    "# --- It√©ration sur les lignes de gdf_world ---\n",
    "for idx, row in gdf_world.iterrows():\n",
    "    name = str(row['name'])\n",
    "    french = str(row.get('french_short', '') or '')\n",
    "    candidates = list(countries)\n",
    "\n",
    "    # --- 1Ô∏è‚É£ Correspondance exacte ---\n",
    "    exact_match = next(\n",
    "        (c for c in candidates if c.lower() == name.lower() or c.lower() == french.lower()), \n",
    "        None\n",
    "    )\n",
    "    if exact_match:\n",
    "        gdf_world.at[idx, 'Country'] = exact_match\n",
    "        continue\n",
    "\n",
    "    # --- 2Ô∏è‚É£ Correspondance par inclusion (dans un sens ou l‚Äôautre) ---\n",
    "    inclusions = [\n",
    "        c for c in candidates\n",
    "        if name.lower() in c.lower() or c.lower() in name.lower()\n",
    "        or french.lower() in c.lower() or c.lower() in french.lower()\n",
    "    ]\n",
    "    if inclusions:\n",
    "        print(f\"\\nüåç Nom : {name} (FR : {french})\")\n",
    "        print(\"‚Üí Correspondances par inclusion :\")\n",
    "        for i, c in enumerate(inclusions):\n",
    "            print(f\"  [{i}] {c}\")\n",
    "        choix = input(\"S√©lectionner le num√©ro de la correspondance √† valider (Entr√©e pour ignorer) : \")\n",
    "\n",
    "        if choix.isdigit() and int(choix) < len(inclusions):\n",
    "            gdf_world.at[idx, 'Country'] = inclusions[int(choix)]\n",
    "            print(f\"‚úÖ Correspondance valid√©e (inclusion) : {name} ‚Üí {inclusions[int(choix)]}\")\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"‚ùå Aucune correspondance valid√©e pour {name}\")\n",
    "\n",
    "    # --- 3Ô∏è‚É£ Correspondance floue (difflib) ---\n",
    "    matches_name = find_best_match(name, candidates)\n",
    "    matches_fr = find_best_match(french, candidates) if french else []\n",
    "    all_matches = list(dict.fromkeys(matches_name + matches_fr))  # fusion sans doublons\n",
    "\n",
    "    if all_matches:\n",
    "        print(f\"\\nüåç Nom : {name} (FR : {french})\")\n",
    "        print(\"‚Üí Correspondances floues potentielles dans df_merged['Country'] :\")\n",
    "        for i, c in enumerate(all_matches):\n",
    "            print(f\"  [{i}] {c}\")\n",
    "        choix = input(\"S√©lectionner le num√©ro de la correspondance √† valider (Entr√©e pour ignorer) : \")\n",
    "\n",
    "        if choix.isdigit() and int(choix) < len(all_matches):\n",
    "            gdf_world.at[idx, 'Country'] = all_matches[int(choix)]\n",
    "            print(f\"‚úÖ Correspondance valid√©e (floue) : {name} ‚Üí {all_matches[int(choix)]}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Aucune correspondance valid√©e pour {name}\")\n",
    "\n",
    "print(\"\\n‚úÖ Mise √† jour termin√©e.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dfd33b6a-346c-40e8-aa11-512452fa20bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fichier enregistr√© : C:\\Users\\Aubin\\Documents\\NetZero\\Data\\SIG\\world.geojson\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarde du GeoDataFrame mis √† jour en GeoJSON\n",
    "filepath= base_path/ \"Data\" / 'SIG' / \"world.geojson\"\n",
    "gdf_world = gdf_world.rename(columns={'iso_3166_1_alpha_2_codes': 'Country_code'})\n",
    "\n",
    "gdf_world.to_file(filepath, driver=\"GeoJSON\", encoding=\"utf-8\")\n",
    "\n",
    "print(f\"‚úÖ Fichier enregistr√© : {filepath}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059cd82c-c81f-4da8-87e5-890ec39d6e51",
   "metadata": {},
   "source": [
    "### GO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1fa60f46-41a8-40d0-ad27-bd016fa9e379",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fusion termin√©e.\n",
      "Lignes fusionn√©es : 40194\n",
      "Lignes sans correspondance de code pays AVANT mapping manuel : 8526\n",
      "Lignes sans correspondance de code pays APR√àS mapping manuel : 7482\n"
     ]
    }
   ],
   "source": [
    "# Fusionner avec df_merged\n",
    "df_merged = df_long.merge(\n",
    "    gdf_world[['Country_code', 'Country']],\n",
    "    on='Country',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# V√©rifier que la colonne existe\n",
    "if 'Country_code' not in df_merged.columns:\n",
    "    df_merged['Country_code'] = pd.NA\n",
    "\n",
    "print(\"‚úÖ Fusion termin√©e.\")\n",
    "print(f\"Lignes fusionn√©es : {len(df_merged)}\")\n",
    "print(f\"Lignes sans correspondance de code pays AVANT mapping manuel : {df_merged['Country_code'].isna().sum()}\")\n",
    "\n",
    "# --- üîß Ajout du mapping manuel pour certains pays ---\n",
    "manual_mapping = {\n",
    "    \"Laos\": \"LA\",\n",
    "    \"Lao People's Democratic Republic\": \"LA\",\n",
    "    \"North Korea\": \"KP\",\n",
    "    \"Democratic People's Republic of Korea\": \"KP\",\n",
    "    \"North Macedonia\": \"MK\",\n",
    "    \"Macedonia\": \"MK\",\n",
    "    \"Occupied Palestinian Territory\": \"PS\",\n",
    "    \"State of Palestine\": \"PS\",\n",
    "    \"South Korea\": \"KR\",\n",
    "    \"Republic of Korea\": \"KR\",\n",
    "    \"United Kingdom\": \"GB\",\n",
    "    \"United Kingdom of Great Britain and Northern Ireland\": \"GB\",\n",
    "    \"Namibia\": \"NAM\"  # ton code personnalis√©\n",
    "}\n",
    "\n",
    "# Appliquer les codes manuels\n",
    "df_merged['Country_code'] = df_merged.apply(\n",
    "    lambda row: manual_mapping.get(row['Country'], row['Country_code']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(f\"Lignes sans correspondance de code pays APR√àS mapping manuel : {df_merged['Country_code'].isna().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "21be66af-e981-47a6-9700-ae446110226a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame sauvegard√© dans C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\LULUCF_Deforestation_GCB.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/Aubin/Documents/NetZero/Data/data_intermediate/LULUCF_Deforestation_GCB.csv')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#enregistrer dans data_intermediate\n",
    "save_long_dataframe(\n",
    "    df_merged,\n",
    "    base_path,\n",
    "    folder='data_intermediate',\n",
    "    indicator=indicator,\n",
    "    source=source\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "05701279-aecc-4816-8b6a-e5ea7e5affc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç Nombre de pays sans correspondance : 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anguilla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aruba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bermuda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bonaire, Saint Eustatius and Saba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>British Virgin Islands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bunkers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Central America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cura√ßao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Czechia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>EU27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Eswatini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Faeroe Islands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>French Polynesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Greenland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Hong Kong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KP Annex B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Kosovo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Macao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Middle East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Montserrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>New Caledonia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Non KP Annex B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Non-OECD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>OECD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Oceania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Russia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Saint Helena</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Saint Pierre and Miquelon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Sint Maarten (Dutch part)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>South America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>South Sudan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Statistical Difference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Taiwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Turks and Caicos Islands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>T√ºrkiye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Viet Nam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Wallis and Futuna Islands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Country\n",
       "0                              Africa\n",
       "1                            Anguilla\n",
       "2                               Aruba\n",
       "3                                Asia\n",
       "4                             Bermuda\n",
       "5   Bonaire, Saint Eustatius and Saba\n",
       "6              British Virgin Islands\n",
       "7                             Bunkers\n",
       "8                     Central America\n",
       "9                             Cura√ßao\n",
       "10                            Czechia\n",
       "11                               EU27\n",
       "12                           Eswatini\n",
       "13                             Europe\n",
       "14                     Faeroe Islands\n",
       "15                   French Polynesia\n",
       "16                          Greenland\n",
       "17                          Hong Kong\n",
       "18                         KP Annex B\n",
       "19                             Kosovo\n",
       "20                              Macao\n",
       "21                        Middle East\n",
       "22                         Montserrat\n",
       "23                      New Caledonia\n",
       "24                     Non KP Annex B\n",
       "25                           Non-OECD\n",
       "26                      North America\n",
       "27                               OECD\n",
       "28                            Oceania\n",
       "29                             Russia\n",
       "30                       Saint Helena\n",
       "31          Saint Pierre and Miquelon\n",
       "32          Sint Maarten (Dutch part)\n",
       "33                      South America\n",
       "34                        South Sudan\n",
       "35             Statistical Difference\n",
       "36                             Taiwan\n",
       "37           Turks and Caicos Islands\n",
       "38                            T√ºrkiye\n",
       "39                                USA\n",
       "40                           Viet Nam\n",
       "41          Wallis and Futuna Islands\n",
       "42                              World"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filtrer les pays sans correspondance\n",
    "countries_without_match = df_merged[df_merged['Country_code'].isna()]['Country'].dropna().drop_duplicates().sort_values()\n",
    "\n",
    "# Afficher le r√©sultat\n",
    "print(f\"üåç Nombre de pays sans correspondance : {len(countries_without_match)}\")\n",
    "display(countries_without_match.to_frame().reset_index(drop=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "58a820ae-e4ab-4f9a-a43d-c245fa4e116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def manual_country_code_match(df_merged, gdf_world, country_codes_path=r'C:\\Users\\Aubin\\Documents\\NetZero\\Data\\SIG\\country_codes_clean.csv'):\n",
    "    \"\"\"\n",
    "    Compl√®te manuellement ou automatiquement les codes ISO (Country_code) pour les pays\n",
    "    de df_merged qui n'ont pas de correspondance dans gdf_world['Country_code'].\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- üîß Mapping manuel forc√© (prioritaire) ---\n",
    "    manual_mapping = {\n",
    "        \"Laos\": \"LA\",\n",
    "        \"Lao People's Democratic Republic\": \"LA\",\n",
    "        \"North Korea\": \"KP\",\n",
    "        \"Democratic People's Republic of Korea\": \"KP\",\n",
    "        \"North Macedonia\": \"MK\",\n",
    "        \"Macedonia\": \"MK\",\n",
    "        \"Occupied Palestinian Territory\": \"PS\",\n",
    "        \"State of Palestine\": \"PS\",\n",
    "        \"South Korea\": \"KR\",\n",
    "        \"Republic of Korea\": \"KR\",\n",
    "        \"United Kingdom\": \"GB\",\n",
    "        \"United Kingdom of Great Britain and Northern Ireland\": \"GB\",\n",
    "        \"Namibia\": \"NAM\"   # (attention : ce n‚Äôest pas le code ISO, mais ce que tu veux)\n",
    "    }\n",
    "\n",
    "    # Charger le fichier CSV des codes ISO\n",
    "    country_codes_df = pd.read_csv(country_codes_path)\n",
    "\n",
    "    # Mapping existant depuis gdf_world\n",
    "    existing_mapping = gdf_world.set_index('Country')['Country_code'].to_dict()\n",
    "\n",
    "    # Mapping depuis CSV\n",
    "    csv_mapping = country_codes_df.set_index('Country')['Alpha-2 code'].to_dict()\n",
    "\n",
    "    # Identifier les pays sans code\n",
    "    unmatched_countries = (\n",
    "        df_merged.loc[df_merged['Country_code'].isna(), 'Country']\n",
    "        .dropna()\n",
    "        .unique()\n",
    "    )\n",
    "\n",
    "    print(f\"\\nüîé {len(unmatched_countries)} pays sans Country_code.\\n\")\n",
    "\n",
    "    for c in unmatched_countries:\n",
    "        print(f\"\\nüåç Pays : {c}\")\n",
    "\n",
    "        # --- 1Ô∏è‚É£ V√©rifier le mapping manuel ---\n",
    "        if c in manual_mapping:\n",
    "            saisie = manual_mapping[c]\n",
    "            print(f\"‚Üí Code trouv√© dans le mapping manuel : {saisie}\")\n",
    "\n",
    "        # --- 2Ô∏è‚É£ V√©rifier le CSV ---\n",
    "        elif c in csv_mapping:\n",
    "            saisie = csv_mapping[c]\n",
    "            print(f\"‚Üí Code trouv√© automatiquement depuis CSV : {saisie}\")\n",
    "\n",
    "        # --- 3Ô∏è‚É£ Chercher dans gdf_world (suggestions partielles) ---\n",
    "        else:\n",
    "            suggestions = gdf_world[gdf_world['Country'].str.contains(c, case=False, na=False)]\n",
    "\n",
    "            if not suggestions.empty:\n",
    "                print(\"‚Üí Suggestions depuis gdf_world :\")\n",
    "                for i, row in suggestions.iterrows():\n",
    "                    print(f\"  [{i}] {row['Country']} ‚Üí {row['Country_code']}\")\n",
    "\n",
    "            # Saisie manuelle\n",
    "            saisie = input(\"Entrer le Country_code ISO correspondant (ou Entr√©e pour ignorer) : \").strip().upper()\n",
    "            if saisie == \"\":\n",
    "                print(\"‚è≠Ô∏è Ignor√©.\")\n",
    "                continue\n",
    "\n",
    "        # Appliquer la saisie\n",
    "        df_merged.loc[df_merged['Country'] == c, 'Country_code'] = saisie\n",
    "        print(f\"‚úÖ Country_code ajout√© : {c} ‚Üí {saisie}\")\n",
    "\n",
    "    print(\"\\n‚úÖ Saisie automatique et manuelle des codes termin√©e.\")\n",
    "    return df_merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "03b85d22-946a-4d1a-8ea2-c24529a4463d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîé 43 pays sans Country_code.\n",
      "\n",
      "\n",
      "üåç Pays : Anguilla\n",
      "‚Üí Code trouv√© automatiquement depuis CSV : AI\n",
      "‚úÖ Country_code ajout√© : Anguilla ‚Üí AI\n",
      "\n",
      "üåç Pays : Aruba\n",
      "‚Üí Code trouv√© automatiquement depuis CSV : AW\n",
      "‚úÖ Country_code ajout√© : Aruba ‚Üí AW\n",
      "\n",
      "üåç Pays : Bermuda\n",
      "‚Üí Code trouv√© automatiquement depuis CSV : BM\n",
      "‚úÖ Country_code ajout√© : Bermuda ‚Üí BM\n",
      "\n",
      "üåç Pays : Bonaire, Saint Eustatius and Saba\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[132]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_merged=\u001b[43mmanual_country_code_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_merged\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgdf_world\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[130]\u001b[39m\u001b[32m, line 67\u001b[39m, in \u001b[36mmanual_country_code_match\u001b[39m\u001b[34m(df_merged, gdf_world, country_codes_path)\u001b[39m\n\u001b[32m     64\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[33m'\u001b[39m\u001b[33mCountry\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ‚Üí \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[33m'\u001b[39m\u001b[33mCountry_code\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# Saisie manuelle\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m saisie = \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEntrer le Country_code ISO correspondant (ou Entr√©e pour ignorer) : \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.strip().upper()\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m saisie == \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     69\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚è≠Ô∏è Ignor√©.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ipykernel\\kernelbase.py:1473\u001b[39m, in \u001b[36mKernel.raw_input\u001b[39m\u001b[34m(self, prompt)\u001b[39m\n\u001b[32m   1471\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1472\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[32m-> \u001b[39m\u001b[32m1473\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1474\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1475\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_shell_parent_ident\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1476\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1477\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1478\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ipykernel\\kernelbase.py:1518\u001b[39m, in \u001b[36mKernel._input_request\u001b[39m\u001b[34m(self, prompt, ident, parent, password)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1516\u001b[39m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[32m   1517\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mInterrupted by user\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1518\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1519\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1520\u001b[39m     \u001b[38;5;28mself\u001b[39m.log.warning(\u001b[33m\"\u001b[39m\u001b[33mInvalid Message:\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "df_merged=manual_country_code_match(df_merged, gdf_world)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c2a037-466c-44e5-aebe-a04be44f28d1",
   "metadata": {},
   "source": [
    "## DF FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e6e752f2-32a6-4bc9-8467-08769b515df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame sauvegard√© dans C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\LULUCF_Forest_Regrowth_GCB.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/Aubin/Documents/NetZero/Data/data_intermediate/LULUCF_Forest_Regrowth_GCB.csv')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#enregistrer dans data_intermediate\n",
    "save_long_dataframe(\n",
    "    df_merged,\n",
    "    base_path,\n",
    "    folder='data_intermediate',\n",
    "    indicator=indicator,\n",
    "    source=source\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "192fd9f7-eab8-41dd-9215-81d4be2f0186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Country</th>\n",
       "      <th>Value</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Indicator</th>\n",
       "      <th>Source</th>\n",
       "      <th>Country_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1960</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>3472860.0</td>\n",
       "      <td>tC</td>\n",
       "      <td>LULUCF Other Emissions</td>\n",
       "      <td>GCB</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1961</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2936880.0</td>\n",
       "      <td>tC</td>\n",
       "      <td>LULUCF Other Emissions</td>\n",
       "      <td>GCB</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1962</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2676090.0</td>\n",
       "      <td>tC</td>\n",
       "      <td>LULUCF Other Emissions</td>\n",
       "      <td>GCB</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1963</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2581340.0</td>\n",
       "      <td>tC</td>\n",
       "      <td>LULUCF Other Emissions</td>\n",
       "      <td>GCB</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1964</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2136740.0</td>\n",
       "      <td>tC</td>\n",
       "      <td>LULUCF Other Emissions</td>\n",
       "      <td>GCB</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12670</th>\n",
       "      <td>2020</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>-1382330.0</td>\n",
       "      <td>tC</td>\n",
       "      <td>LULUCF Other Emissions</td>\n",
       "      <td>GCB</td>\n",
       "      <td>ZW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12671</th>\n",
       "      <td>2021</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>-1024560.0</td>\n",
       "      <td>tC</td>\n",
       "      <td>LULUCF Other Emissions</td>\n",
       "      <td>GCB</td>\n",
       "      <td>ZW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12672</th>\n",
       "      <td>2022</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>-1280580.0</td>\n",
       "      <td>tC</td>\n",
       "      <td>LULUCF Other Emissions</td>\n",
       "      <td>GCB</td>\n",
       "      <td>ZW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12673</th>\n",
       "      <td>2023</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>-1315430.0</td>\n",
       "      <td>tC</td>\n",
       "      <td>LULUCF Other Emissions</td>\n",
       "      <td>GCB</td>\n",
       "      <td>ZW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12674</th>\n",
       "      <td>2024</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>-1334320.0</td>\n",
       "      <td>tC</td>\n",
       "      <td>LULUCF Other Emissions</td>\n",
       "      <td>GCB</td>\n",
       "      <td>ZW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12675 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year      Country      Value Unit               Indicator Source  \\\n",
       "0      1960  Afghanistan  3472860.0   tC  LULUCF Other Emissions    GCB   \n",
       "1      1961  Afghanistan  2936880.0   tC  LULUCF Other Emissions    GCB   \n",
       "2      1962  Afghanistan  2676090.0   tC  LULUCF Other Emissions    GCB   \n",
       "3      1963  Afghanistan  2581340.0   tC  LULUCF Other Emissions    GCB   \n",
       "4      1964  Afghanistan  2136740.0   tC  LULUCF Other Emissions    GCB   \n",
       "...     ...          ...        ...  ...                     ...    ...   \n",
       "12670  2020     Zimbabwe -1382330.0   tC  LULUCF Other Emissions    GCB   \n",
       "12671  2021     Zimbabwe -1024560.0   tC  LULUCF Other Emissions    GCB   \n",
       "12672  2022     Zimbabwe -1280580.0   tC  LULUCF Other Emissions    GCB   \n",
       "12673  2023     Zimbabwe -1315430.0   tC  LULUCF Other Emissions    GCB   \n",
       "12674  2024     Zimbabwe -1334320.0   tC  LULUCF Other Emissions    GCB   \n",
       "\n",
       "      Country_code  \n",
       "0               AF  \n",
       "1               AF  \n",
       "2               AF  \n",
       "3               AF  \n",
       "4               AF  \n",
       "...            ...  \n",
       "12670           ZW  \n",
       "12671           ZW  \n",
       "12672           ZW  \n",
       "12673           ZW  \n",
       "12674           ZW  \n",
       "\n",
       "[12675 rows x 7 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76da72ef-a7d2-472d-9207-6065cd8c1223",
   "metadata": {},
   "source": [
    "###  CHANGE UNIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8c21425b-ea49-430b-a79c-42f6b9413628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def browse_and_convert_units(\n",
    "        base_path,\n",
    "        folder_in=\"data_intermediate\",\n",
    "        value_col=\"Value\",\n",
    "        unit_col=\"Unit\",\n",
    "        sep=\",\",\n",
    "        encoding=\"utf-8\"\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Parcourt tous les fichiers CSV du dossier, demande si on veut changer l'unit√©\n",
    "    et applique la conversion directement dans chaque fichier.\n",
    "\n",
    "    Param√®tres :\n",
    "    - base_path : Path de base\n",
    "    - folder_in : dossier contenant les CSV\n",
    "    - value_col : colonne des valeurs\n",
    "    - unit_col : colonne de l'unit√©\n",
    "    \"\"\"\n",
    "\n",
    "    import pandas as pd\n",
    "    from pathlib import Path\n",
    "    import glob\n",
    "\n",
    "    # Construire le chemin des fichiers\n",
    "    folder_path = base_path / \"Data\" / folder_in\n",
    "    files = glob.glob(str(folder_path / \"*.csv\"))\n",
    "\n",
    "    if not files:\n",
    "        print(f\"Aucun fichier CSV trouv√© dans {folder_path}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"üîç {len(files)} fichiers trouv√©s dans {folder_path}\\n\")\n",
    "\n",
    "    for file in files:\n",
    "        print(\"‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\")\n",
    "        print(f\"üìÑ Fichier : {file}\")\n",
    "\n",
    "        # Charger le fichier\n",
    "        df = pd.read_csv(file, sep=sep, encoding=encoding)\n",
    "\n",
    "        # V√©rification des colonnes\n",
    "        if value_col not in df.columns or unit_col not in df.columns:\n",
    "            print(f\"‚ö†Ô∏è  Fichier ignor√© (colonnes manquantes '{value_col}' ou '{unit_col}')\\n\")\n",
    "            continue\n",
    "\n",
    "        # Unit√© actuelle\n",
    "        current_unit = df[unit_col].iloc[0]\n",
    "        print(f\"üîç Unit√© actuelle : {current_unit}\")\n",
    "\n",
    "        # Demander si on veut convertir\n",
    "        resp = input(\"üëâ Voulez-vous changer l'unit√© ? (o/n) : \").strip().lower()\n",
    "        if resp != \"o\":\n",
    "            print(\"‚û° Aucun changement pour ce fichier.\\n\")\n",
    "            continue\n",
    "\n",
    "        # Facteur multiplicatif\n",
    "        while True:\n",
    "            try:\n",
    "                factor = float(input(\"‚û° Facteur multiplicatif : \"))\n",
    "                break\n",
    "            except ValueError:\n",
    "                print(\"‚ùå Entrer un nombre valide.\")\n",
    "\n",
    "        # Nouvelle unit√©\n",
    "        new_unit = input(\"‚û° Nouvelle unit√© : \").strip()\n",
    "        if new_unit == \"\":\n",
    "            print(\"‚ùå Unit√© vide ‚Äî fichier non modifi√©.\\n\")\n",
    "            continue\n",
    "\n",
    "        # Appliquer la conversion\n",
    "        print(f\"üîÑ Conversion : {value_col} √ó {factor}\")\n",
    "        df[value_col] = df[value_col] * factor\n",
    "        df[unit_col] = new_unit\n",
    "\n",
    "        # Sauvegarder\n",
    "        df.to_csv(file, sep=sep, index=False, encoding=encoding)\n",
    "        print(f\"üíæ Fichier mis √† jour : {file}\\n\")\n",
    "\n",
    "    print(\"üéâ Conversion termin√©e pour tous les fichiers.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c90026e6-ecdc-4270-b02b-12ea1d3d035f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç 2 fichiers trouv√©s dans C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\n",
      "\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "üìÑ Fichier : C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\Fossil_CO2_emissions_GCB.csv\n",
      "üîç Unit√© actuelle : tC\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üëâ Voulez-vous changer l'unit√© ? (o/n) :  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚û° Aucun changement pour ce fichier.\n",
      "\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "üìÑ Fichier : C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\LULUCF_Net_emissions_GCB.csv\n",
      "üîç Unit√© actuelle : MtC/year\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üëâ Voulez-vous changer l'unit√© ? (o/n) :  o\n",
      "‚û° Facteur multiplicatif :  1000000\n",
      "‚û° Nouvelle unit√© :  tC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Conversion : Value √ó 1000000.0\n",
      "üíæ Fichier mis √† jour : C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\LULUCF_Net_emissions_GCB.csv\n",
      "\n",
      "üéâ Conversion termin√©e pour tous les fichiers.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "browse_and_convert_units(base_path, folder_in=\"data_intermediate\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dbf632-09ca-4a6b-95ea-9fda40633636",
   "metadata": {},
   "source": [
    "### CONCAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8f11015-a58b-4c94-be78-cd2a1a4bea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_intermediate_files(base_path, folder_in=\"data_intermediate\", folder_out=\"data_final\", final_filename=\"data_final.csv\", sep=',', encoding='utf-8'):\n",
    "    \"\"\"\n",
    "    Concat√®ne tous les fichiers CSV dans un dossier interm√©diaire et sauvegarde le r√©sultat final.\n",
    "    Affiche les fichiers trouv√©s et le nombre de lignes par fichier.\n",
    "\n",
    "    Param√®tres :\n",
    "    - folder_in : dossier contenant les fichiers CSV interm√©diaires\n",
    "    - folder_out : dossier o√π sauvegarder le fichier final\n",
    "    - final_filename : nom du fichier CSV final\n",
    "    - sep : s√©parateur CSV\n",
    "    - encoding : encodage du fichier\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from pathlib import Path\n",
    "    import glob\n",
    "\n",
    "    # Construire le chemin des fichiers\n",
    "    folder_path = base_path / \"Data\" / folder_in\n",
    "    files = glob.glob(str(folder_path / \"*.csv\"))\n",
    "\n",
    "    if not files:\n",
    "        print(f\"Aucun fichier CSV trouv√© dans {folder_path}\")\n",
    "        return None\n",
    "\n",
    "    print(\"Fichiers trouv√©s et nombre de lignes :\")\n",
    "    dfs = []\n",
    "    for f in files:\n",
    "        df = pd.read_csv(f, sep=sep, encoding=encoding)\n",
    "        print(f\"{f} colonnes : {df.columns.tolist()}\")\n",
    "        print(f\"- {f} : {len(df)} lignes\")\n",
    "        dfs.append(df)\n",
    "\n",
    "    # Concat√©ner tous les fichiers\n",
    "    df_final = pd.concat(dfs, ignore_index=True)\n",
    "    print(f\"{len(files)} fichiers fusionn√©s pour obtenir {len(df_final)} lignes au total.\")\n",
    "\n",
    "    # Sauvegarder le r√©sultat final\n",
    "    save_path = base_path / \"Data\" / folder_out / final_filename\n",
    "    save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df_final.to_csv(save_path, sep=sep, index=False, encoding=encoding)\n",
    "\n",
    "    print(f\"DataFrame final sauvegard√© dans {save_path}\")\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f350ad06-959b-4e03-8b3d-bedfc8bc369b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichiers trouv√©s et nombre de lignes :\n",
      "C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\Fossil_CO2_emissions_GCB.csv colonnes : ['Year', 'Country', 'Value', 'Unit', 'Indicator', 'Source', 'Country_code']\n",
      "- C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\Fossil_CO2_emissions_GCB.csv : 24636 lignes\n",
      "C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\LULUCF_Net_emissions_GCB.csv colonnes : ['Year', 'Country', 'Value', 'Unit', 'Indicator', 'Source', 'Country_code']\n",
      "- C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\LULUCF_Net_emissions_GCB.csv : 12480 lignes\n",
      "2 fichiers fusionn√©s pour obtenir 37116 lignes au total.\n",
      "DataFrame final sauvegard√© dans C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_final\\data_final_all.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Country</th>\n",
       "      <th>Value</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Indicator</th>\n",
       "      <th>Source</th>\n",
       "      <th>Country_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1949</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>tC</td>\n",
       "      <td>Fossil CO2 emissions</td>\n",
       "      <td>GCB</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1950</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>tC</td>\n",
       "      <td>Fossil CO2 emissions</td>\n",
       "      <td>GCB</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1951</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>tC</td>\n",
       "      <td>Fossil CO2 emissions</td>\n",
       "      <td>GCB</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1952</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>tC</td>\n",
       "      <td>Fossil CO2 emissions</td>\n",
       "      <td>GCB</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1953</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>29000.0</td>\n",
       "      <td>tC</td>\n",
       "      <td>Fossil CO2 emissions</td>\n",
       "      <td>GCB</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year      Country    Value Unit             Indicator Source Country_code\n",
       "0  1949  Afghanistan   4000.0   tC  Fossil CO2 emissions    GCB           AF\n",
       "1  1950  Afghanistan  23000.0   tC  Fossil CO2 emissions    GCB           AF\n",
       "2  1951  Afghanistan  25000.0   tC  Fossil CO2 emissions    GCB           AF\n",
       "3  1952  Afghanistan  25000.0   tC  Fossil CO2 emissions    GCB           AF\n",
       "4  1953  Afghanistan  29000.0   tC  Fossil CO2 emissions    GCB           AF"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concat√©ner toutes les bases de donn√©es dans data_intermediate et enregistrer dans data_final\n",
    "df_final = concat_intermediate_files(\n",
    "    base_path,\n",
    "    folder_in=\"data_intermediate\",\n",
    "    folder_out=\"data_final\",\n",
    "    final_filename=\"data_final_all.csv\"\n",
    ")\n",
    "df_final.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3caaae60-8a2f-4d8d-b29f-f9f1190fa47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_and_add_cumulative(base_path,\n",
    "                              folder_in=\"data_intermediate\",\n",
    "                              folder_out=\"data_final\",\n",
    "                              final_filename=\"data_final.csv\",\n",
    "                              sep=\",\",\n",
    "                              encoding=\"utf-8\",\n",
    "                              group_cols=[\"Country_code\"]):\n",
    "    \"\"\"\n",
    "    Parcourt un dossier contenant des fichiers CSV, ajoute Type='Annual',\n",
    "    puis cr√©e une version Cumulative en cumulant la colonne 'Value' sur 'Year',\n",
    "    en respectant le pays (Code_country).\n",
    "\n",
    "    Param√®tres :\n",
    "    - group_cols : colonnes pour grouper les valeurs afin de cumuler (inclut Code_country).\n",
    "    \"\"\"\n",
    "\n",
    "    import pandas as pd\n",
    "    from pathlib import Path\n",
    "    import glob\n",
    "\n",
    "    folder_path = base_path / \"Data\" / folder_in\n",
    "    files = glob.glob(str(folder_path / \"*.csv\"))\n",
    "\n",
    "    if not files:\n",
    "        print(f\"Aucun fichier CSV trouv√© dans {folder_path}\")\n",
    "        return None\n",
    "\n",
    "    dfs_all = []\n",
    "\n",
    "    print(\"Fichiers trouv√©s :\")\n",
    "    for f in files:\n",
    "        print(f\"‚Üí {f}\")\n",
    "\n",
    "        df = pd.read_csv(f, sep=sep, encoding=encoding)\n",
    "\n",
    "        # V√©rifications\n",
    "        required_cols = [\"Year\", \"Value\", \"Country_code\"]\n",
    "        for col in required_cols:\n",
    "            if col not in df.columns:\n",
    "                print(f\"‚ö†Ô∏è Fichier ignor√© : colonne manquante '{col}' ‚Üí {f}\")\n",
    "                break\n",
    "        else:\n",
    "            # ANNUAL\n",
    "            df_annual = df.copy()\n",
    "            df_annual[\"Type\"] = \"Annual\"\n",
    "\n",
    "            # CUMULATIVE\n",
    "            df_cum = df.copy()\n",
    "            df_cum[\"Type\"] = \"Cumulative\"\n",
    "\n",
    "            # Cumul par Code_country + autres group_cols\n",
    "            df_cum[\"Value\"] = (\n",
    "                df_cum\n",
    "                .sort_values(\"Year\")\n",
    "                .groupby(group_cols)[\"Value\"]\n",
    "                .cumsum()\n",
    "            )\n",
    "\n",
    "            # Combine Annual + Cumulative\n",
    "            dfs_all.append(pd.concat([df_annual, df_cum], ignore_index=True))\n",
    "\n",
    "    # Fusion de tous les fichiers\n",
    "    df_final = pd.concat(dfs_all, ignore_index=True)\n",
    "\n",
    "    # Sauvegarde\n",
    "    save_path = base_path / \"Data\" / folder_out / final_filename\n",
    "    save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df_final.to_csv(save_path, sep=sep, index=False, encoding=encoding)\n",
    "\n",
    "    print(f\"\\n‚úî Donn√©es fusionn√©es et sauvegard√©es dans : {save_path}\")\n",
    "    print(f\"‚úî Total : {len(df_final):,} lignes\")\n",
    "\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e8c94fd3-d746-48fc-b02e-7916f7060ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichiers trouv√©s :\n",
      "‚Üí C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\LULUCF_Deforestation_GCB.csv\n",
      "‚Üí C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\LULUCF_Forest_Regrowth_GCB.csv\n",
      "‚Üí C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\LULUCF_Net_emissions_GCB.csv\n",
      "‚Üí C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\LULUCF_Other_Emissions_GCB.csv\n",
      "‚Üí C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\LULUCF_Peat_Emissions_GCB.csv\n",
      "‚Üí C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\LULUCF_Wood_Harvesting_GCB.csv\n",
      "\n",
      "‚úî Donn√©es fusionn√©es et sauvegard√©es dans : C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_final\\data_final_all.csv\n",
      "‚úî Total : 151,710 lignes\n"
     ]
    }
   ],
   "source": [
    "df_final=concat_and_add_cumulative(base_path,\n",
    "                              folder_in=\"data_intermediate\",\n",
    "                              folder_out=\"data_final\",\n",
    "                              final_filename=\"data_final_all.csv\",\n",
    "                              sep=\",\",\n",
    "                              encoding=\"utf-8\",\n",
    "                              group_cols=[\"Country_code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f82cbf50-a98d-4619-80f7-4b68c0b19456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\Fossil_CO2_emissions_GCB.csv\n",
      "File loaded: C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\Fossil_CO2_emissions_GCB.csv\n",
      "------------------------------------------------------------\n",
      "Countries missing Country_code:\n",
      " - Namibia\n",
      "\n",
      "Please enter the missing Country_code values.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Country_code for 'Namibia':  NAM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated file saved!\n",
      " ‚Üí C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\Fossil_CO2_emissions_GCB.csv\n",
      "Loading data from: C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\LULUCF_Net_emissions_GCB.csv\n",
      "File loaded: C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\LULUCF_Net_emissions_GCB.csv\n",
      "------------------------------------------------------------\n",
      "Countries missing Country_code:\n",
      " - Namibia\n",
      "\n",
      "Please enter the missing Country_code values.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Country_code for 'Namibia':  NAM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated file saved!\n",
      " ‚Üí C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_intermediate\\LULUCF_Net_emissions_GCB.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "folder = base_path / 'Data' / 'data_intermediate'\n",
    "\n",
    "# Loop over all files in the folder (e.g., CSV files)\n",
    "for filepath in folder.glob('*.csv'):  # adjust pattern if needed\n",
    "     # read the file\n",
    "    df_fixed = fix_missing_country_codes(filepath)  # apply your function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fd3b0a-faf3-4bac-82f6-7f5a2fa8dcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHECK NO COUNTRY CODE BUT DATA AND UPDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d0737ea7-cb9f-4c61-96b3-d1c9e3a3cfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def import_csv_data(filepath):\n",
    "    print(\"Loading data from:\", filepath.resolve())  # debug\n",
    "    df = pd.read_csv(filepath)\n",
    "    return df\n",
    "    \n",
    "def fix_missing_country_codes(filepath, country_col=\"Country\", code_col=\"Country_code\"):\n",
    "    \"\"\"\n",
    "    Load a file, detect countries missing country_code, ask user for the code,\n",
    "    update the file, and save the corrected version.\n",
    "    \"\"\"\n",
    "    # Load file\n",
    "    df = import_csv_data(filepath)\n",
    "    print(f\"File loaded: {filepath}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # Identify missing codes\n",
    "    missing_mask = df[code_col].isna() | (df[code_col].astype(str).str.strip() == \"\")\n",
    "    missing_countries = df.loc[missing_mask, country_col].unique()\n",
    "\n",
    "    if len(missing_countries) == 0:\n",
    "        print(\"No missing Country_code found. Nothing to fix.\")\n",
    "        return df\n",
    "\n",
    "    print(\"Countries missing Country_code:\")\n",
    "    for c in missing_countries:\n",
    "        print(f\" - {c}\")\n",
    "\n",
    "    print(\"\\nPlease enter the missing Country_code values.\\n\")\n",
    "\n",
    "    # Ask manually for each missing country\n",
    "    replacement_map = {}\n",
    "    for country in missing_countries:\n",
    "        code = input(f\"Enter Country_code for '{country}': \").strip()\n",
    "        replacement_map[country] = code\n",
    "\n",
    "    # Apply replacements\n",
    "    for country, code in replacement_map.items():\n",
    "        df.loc[df[country_col] == country, code_col] = code\n",
    "\n",
    "    # Save file (overwrite)\n",
    "    df.to_csv(filepath, index=False)\n",
    "    print(\"\\nUpdated file saved!\")\n",
    "    print(f\" ‚Üí {filepath}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a6e4796-9273-47ca-a6e2-7bdaeb3f2581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_final\\data_final_all_norm.csv\n",
      "File loaded: C:\\Users\\Aubin\\Documents\\NetZero\\Data\\data_final\\data_final_all_norm.csv\n",
      "------------------------------------------------------------\n",
      "No missing Country_code found. Nothing to fix.\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
